{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 法律語法形式化\n",
    "- version: 20250314\n",
    "- spec version: 3.1\n",
    "- history:\n",
    "    - 20250312: 讀寫 json, 基本支援 LLM 建構 json\n",
    "    - 20250313: 用 code 產生小架構的法規，增加管理功能\n",
    "    - 20250314: 加入 query 的一些功能，順便測試一下資料\n",
    "    - 20250319: 改善 prompt, 生成更正確，加幾個法\n",
    "\n",
    "- env: 2504\n",
    "## 起始化-物件與functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from enum import Enum\n",
    "import re\n",
    "import os\n",
    "\n",
    "dir_txt = \"txt\"\n",
    "dir_json = \"json\"\n",
    "def get_law_names_from_directory(directory_path):\n",
    "    \"\"\"\n",
    "    從目錄中取得所有法規名稱的列表\n",
    "    :param directory_path: 目錄的路徑\n",
    "    :return: 法規名稱的列表\n",
    "    \"\"\"\n",
    "    law_names = set()\n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory not found: {directory_path}\")\n",
    "        return list(law_names)\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\"_law_regulation.json\"):\n",
    "            law_name = filename.split(\"_law_regulation\")[0]\n",
    "            law_names.add(law_name)\n",
    "    return list(law_names)\n",
    "def handle_regex(regex,file_path,type=\"col2\"): \n",
    "    \"\"\"\n",
    "    return lines\n",
    "    \"\"\"\n",
    "    print(f\"parse file_path:{file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            test_str = file.read()\n",
    "    #print(test_str)\n",
    "    matches = re.finditer(regex, test_str, re.DOTALL) #re.MULTILINE\n",
    "    lines = []\n",
    "    if type==\"col2\": #regex=\"\\*\\*Q：\\*\\*(.*)\\n\\*\\*A：\\*\\*(.*)\\n\"\n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            for groupNum in range(0, len(match.groups())):\n",
    "                groupNum = groupNum + 1\n",
    "                mark = \"Q\" if groupNum==1 else \"A\"\n",
    "                group = match.group(groupNum).replace(\"*\",\"\")\n",
    "                print_str = f\"{mark}:{group}\"\n",
    "                print(print_str ) \n",
    "                lines.append(print_str)\n",
    "    if type==\"col1\":\n",
    "        \n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            \n",
    "            for groupNum in range(0, len(match.groups())):\n",
    "                groupNum = groupNum + 1\n",
    "                group = match.group(groupNum)\n",
    "                print_str = f\"{group}\"\n",
    "                #print(print_str ) \n",
    "                lines.append(print_str)\n",
    "    return lines    \n",
    "\n",
    "# Helper function: Load JSON data from file\n",
    "def load_json_data(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"JSON format error: {filepath}\")\n",
    "        return None\n",
    "    \n",
    "class ConceptCategory(Enum):\n",
    "    \"\"\"Legal concept categories enumeration.\"\"\"\n",
    "    CORE_CONCEPT_DEFINITION = \"核心概念 - 定義\" # You can keep Chinese values for display if needed\n",
    "    # ... 其他類別 (other categories)\n",
    "\n",
    "class LawMetadata:\n",
    "    \"\"\"\n",
    "    Law MetaData object, used to integrate different types of law information.\n",
    "    \"\"\"\n",
    "    def __init__(self, law_name = None, law_regulation=None, legal_concepts=None, hierarchy_relations=None, law_relations=None, law_articles=None):\n",
    "        \"\"\"\n",
    "        Initializes LawMetaData object.\n",
    "\n",
    "        Args:\n",
    "            law_regulation (dict, optional): Law regulation metadata, expected as a single dict. Defaults to None.\n",
    "            # ... other args\n",
    "        \"\"\"\n",
    "        self.law_regulation = law_regulation or {}\n",
    "        self.legal_concepts = legal_concepts or []\n",
    "        self.hierarchy_relations = hierarchy_relations or []\n",
    "        self.law_relations = law_relations or []\n",
    "        self.law_articles = law_articles or []\n",
    "\n",
    "        # PCode handling: Ensure '代號' is the PCode\n",
    "        pcode_val = None\n",
    "        if self.law_regulation:\n",
    "            pcode_keys = ['PCode', 'pcode'] # Case-sensitive check for explicit PCode\n",
    "            for p_key in pcode_keys:\n",
    "                if p_key in self.law_regulation:\n",
    "                    pcode_val = self.law_regulation[p_key]\n",
    "                    break\n",
    "            current_daihao = self.law_regulation.get('代號')\n",
    "            if pcode_val and current_daihao != pcode_val:\n",
    "                # Warning: Law regulation '代號' might be overwritten by explicit PCode if they differ.\n",
    "                # This print might occur before self.law_name is fully determined if '法規名稱' is also missing.\n",
    "                # print(f\"Warning: Law regulation '代號' ({current_daihao}) differs from explicit PCode ({pcode_val}). Using explicit PCode for '代號'. Law: {self.law_regulation.get('法規名稱')}\")\n",
    "                self.law_regulation['代號'] = pcode_val\n",
    "            elif not current_daihao and pcode_val: # '代號' is missing, but PCode is found\n",
    "                self.law_regulation['代號'] = pcode_val\n",
    "            # If pcode_val is None, '代號' (if it exists) is assumed to be the pcode.\n",
    "\n",
    "        self.law_name = law_name or self.law_regulation.get(\"法規名稱\") \n",
    "        if not self.law_name and self.law_regulation.get('代號'):\n",
    "             # Fallback for law_name if '法規名稱' is missing but '代號' (PCode) exists\n",
    "             self.law_name = self.law_regulation.get('代號') \n",
    "        elif not self.law_name:\n",
    "             self.law_name = \"default_law_name_if_all_else_fails\"\n",
    "        \n",
    "        self.short_name = self.law_name\n",
    "\n",
    "    @classmethod\n",
    "    def from_json_files(cls, law_regulation, legal_concepts, hierarchy_relations, law_relations, law_articles):\n",
    "        \"\"\"\n",
    "        Reads law MetaData from separate JSON files.\n",
    "        \"\"\"\n",
    "        law_regulation_data = load_json_data(law_regulation)\n",
    "        # PCode handling for data loaded from JSON\n",
    "        if law_regulation_data:\n",
    "            pcode_json_val = None\n",
    "            pcode_json_keys = ['PCode', 'pcode']\n",
    "            for p_key in pcode_json_keys:\n",
    "                if p_key in law_regulation_data:\n",
    "                    pcode_json_val = law_regulation_data[p_key]\n",
    "                    break\n",
    "            current_daihao_json = law_regulation_data.get('代號')\n",
    "            law_name_for_warning = law_regulation_data.get('法規名稱', law_regulation.split('/')[-1].split('_law_regulation.json')[0])\n",
    "            if pcode_json_val:\n",
    "                if current_daihao_json != pcode_json_val:\n",
    "                    print(f\"Warning: '代號' ({current_daihao_json}) in JSON differs from PCode ({pcode_json_val}). Setting '代號' to PCode. Law: {law_name_for_warning}\")\n",
    "                    law_regulation_data['代號'] = pcode_json_val\n",
    "            elif not current_daihao_json:\n",
    "                print(f\"Warning: PCode ('PCode' or 'pcode') or '代號' not found in {law_regulation} for {law_name_for_warning}. DB operations might fail if '代號' is not later set to a valid PCode.\")\n",
    "        \n",
    "        legal_concepts_data = load_json_data(legal_concepts)\n",
    "        hierarchy_relations_data = load_json_data(hierarchy_relations)\n",
    "        law_relations_data = load_json_data(law_relations)\n",
    "        law_articles_data = load_json_data(law_articles)\n",
    "\n",
    "        if not all([law_regulation_data, law_articles_data]):\n",
    "            print(f\"Error: Core data (regulation or articles) missing for one of the paths provided.\")\n",
    "            print(f\"Paths: LR:{law_regulation}, LC:{legal_concepts}, LH:{hierarchy_relations}, LRel:{law_relations}, LA:{law_articles}\")\n",
    "            return None\n",
    "        \n",
    "        if legal_concepts_data is None: legal_concepts_data = []\n",
    "        if hierarchy_relations_data is None: hierarchy_relations_data = []\n",
    "        if law_relations_data is None: law_relations_data = []\n",
    "\n",
    "        return cls(\n",
    "            law_regulation=law_regulation_data,\n",
    "            legal_concepts=legal_concepts_data,\n",
    "            hierarchy_relations=hierarchy_relations_data,\n",
    "            law_relations=law_relations_data,\n",
    "            law_articles=law_articles_data\n",
    "        )\n",
    "    \n",
    "\n",
    "    def to_json_files(self, output_prefix=\"gpa\"):\n",
    "        \"\"\"\n",
    "        Exports LawMetaData object to separate JSON files with law name prefix.\n",
    "        \"\"\"\n",
    "        if not output_prefix:\n",
    "            output_prefix = self.law_name \n",
    "\n",
    "        filepaths = {\n",
    "            \"law_regulation\": f\"{output_prefix}_law_regulation.json\",\n",
    "            \"legal_concepts\": f\"{output_prefix}_legal_concepts.json\",\n",
    "            \"hierarchy_relations\": f\"{output_prefix}_hierarchy_relations.json\",\n",
    "            \"law_relations\": f\"{output_prefix}_law_relations.json\",\n",
    "            \"law_articles\": f\"{output_prefix}_law_articles.json\"\n",
    "        }\n",
    "\n",
    "        data_to_export = {\n",
    "            \"law_regulation\": self.law_regulation,\n",
    "            \"legal_concepts\": [\n",
    "                {**concept, \"概念類別\": concept[\"概念類別\"].value if isinstance(concept.get(\"概念類別\"), ConceptCategory) else concept.get(\"概念類別\")}\n",
    "                for concept in self.legal_concepts\n",
    "            ],\n",
    "            \"hierarchy_relations\": self.hierarchy_relations,\n",
    "            \"law_relations\": self.law_relations,\n",
    "            \"law_articles\": self.law_articles\n",
    "        }\n",
    "\n",
    "        for key, filepath in filepaths.items():\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data_to_export[key], f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Exported all components for '{self.law_name}' with prefix '{output_prefix}'.\")\n",
    "\n",
    "    def renew_id(self):\n",
    "        # law_id = f\"LT_{self.law_name}\" # This format is for the old 'code' field.\n",
    "        # self.law_regulation[\"代號\"]=law_id # '代號' should now be PCode, not overwritten here.\n",
    "        # PCode is sourced from JSON or __init__; renew_id should not overwrite it with LT_lawname format.\n",
    "        \n",
    "        # Ensure self.law_name is based on '法規名稱' for consistent ID generation below\n",
    "        # self.law_name is already set in __init__ based on 法規名稱 or PCode as fallback.\n",
    "\n",
    "        for article in self.law_articles:\n",
    "            article_code_current = article.get(\"代號\", \"\")\n",
    "            if not article_code_current.startswith(\"LA_\"):\n",
    "                article_id = f\"LA_{self.law_name}_{article.get('條號', 'UnknownArticle')}\"\n",
    "                article[\"代號\"]=article_id\n",
    "        for concept in self.legal_concepts:\n",
    "            concept_code_current = concept.get(\"代號\", \"\")\n",
    "            if not concept_code_current.startswith(\"LC_\"):\n",
    "                concept_id = f\"LC_{self.law_name}_{concept.get('詞彙名稱', 'UnknownConcept')}\"\n",
    "                concept['代號']=concept_id\n",
    "        seq = 1\n",
    "        for relation in self.law_relations:\n",
    "            relation_code_current = relation.get(\"代號\", \"\")\n",
    "            if not relation_code_current.startswith(\"LR_\"):\n",
    "                relation_id = f\"LR_{self.law_name}_{seq}\"\n",
    "                relation['代號']=relation_id\n",
    "            seq += 1\n",
    "        seq_hier = 1 \n",
    "        for hierarchy in self.hierarchy_relations:\n",
    "            hier_code_current = hierarchy.get(\"關係代號\", \"\")\n",
    "            if not hier_code_current.startswith(\"LH_\"):\n",
    "                hierarchy_id = f\"LH_{self.law_name}_{hierarchy.get('關聯法規', 'UnknownRelatedLaw')}_{seq_hier}\"\n",
    "                hierarchy['關係代號']=hierarchy_id\n",
    "            seq_hier +=1\n",
    "        # Use PCode for this message if available, otherwise law_name\n",
    "        identifier_for_message = self.law_regulation.get('代號', self.law_name)\n",
    "        print(f\"IDs renewed for LawMetadata: {identifier_for_message}\")\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"LawMetadata(law_name='{self.law_regulation.get('法規名稱', 'N/A')}', concept_count={len(self.legal_concepts)}, ...)\"\n",
    "\n",
    "class LawMetadataMgr:\n",
    "    def __init__(self, db_conn=None):\n",
    "        self.lms = {}\n",
    "        self.short_names = {}\n",
    "        self.dir_json = \"json\"\n",
    "        self.db_conn = db_conn\n",
    "        if self.db_conn:\n",
    "            print(\"LawMetadataMgr initialized with a database connection.\")\n",
    "        else:\n",
    "            print(\"LawMetadataMgr initialized without a database connection (JSON mode only).\")\n",
    "\n",
    "    def add_lm(self, lm , short_name=None):\n",
    "        if not lm or not lm.law_name or not lm.law_regulation.get('法規名稱'):\n",
    "            # Check if PCode ('代號') exists as a fallback for identifying the law regulation\n",
    "            if not lm or not lm.law_regulation or not lm.law_regulation.get('代號'):\n",
    "                 print(\"Error: Cannot add invalid or incomplete LawMetadata object (missing 法規名稱 and 代號).\")\n",
    "                 return\n",
    "            elif not lm.law_name:\n",
    "                 # If law_name is missing but PCode exists, try to use PCode as name for manager key\n",
    "                 lm.law_name = lm.law_regulation.get('代號')\n",
    "                 if not lm.law_name: # Still no identifier\n",
    "                    print(\"Error: Cannot add invalid or incomplete LawMetadata object (PCode also missing).\")\n",
    "                    return\n",
    "        \n",
    "        actual_short_name = short_name if short_name else lm.law_name\n",
    "        lm.short_name = actual_short_name\n",
    "        \n",
    "        self.short_names[actual_short_name] = lm.law_name \n",
    "        self.lms[lm.law_name] = lm\n",
    "        print(f\"Added '{lm.law_name}' (short: '{actual_short_name}') to in-memory manager.\")\n",
    "\n",
    "        if self.db_conn:\n",
    "            # Use PCode ('代號') for DB operations if available\n",
    "            pcode_for_db = lm.law_regulation.get('代號', lm.law_name) \n",
    "            print(f\"DB connection found. Attempting to upsert LawMetadata for '{pcode_for_db}' to database.\")\n",
    "            try:\n",
    "                success = upsert_law_metadata_to_db(lm, self.db_conn)\n",
    "                if success:\n",
    "                    print(f\"Successfully upserted '{pcode_for_db}' to database.\")\n",
    "                else:\n",
    "                    print(f\"Warning: Failed to upsert '{pcode_for_db}' to database. It remains in memory only.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during DB upsert for '{pcode_for_db}': {e}. It remains in memory only.\")\n",
    "\n",
    "    def remove_lm(self, law_name_or_short_name):\n",
    "        law_name_to_remove = self.short_names.get(law_name_or_short_name, law_name_or_short_name)\n",
    "        \n",
    "        if law_name_to_remove in self.lms:\n",
    "            lm_to_remove = self.lms[law_name_to_remove]\n",
    "            # Use PCode ('代號') for deletion if available\n",
    "            pcode_to_delete = lm_to_remove.law_regulation.get('代號', law_name_to_remove)\n",
    "            \n",
    "            del self.lms[law_name_to_remove]\n",
    "            # Clean up short_names mapping\n",
    "            keys_to_del_from_short_names = [k for k, v in self.short_names.items() if v == law_name_to_remove]\n",
    "            for k in keys_to_del_from_short_names:\n",
    "                del self.short_names[k]\n",
    "\n",
    "            print(f\"Removed '{law_name_to_remove}' (PCode: {pcode_to_delete}) from in-memory manager.\")\n",
    "\n",
    "            if self.db_conn:\n",
    "                if pcode_to_delete:\n",
    "                    print(f\"DB connection found. Attempting to delete LawMetadata for pcode '{pcode_to_delete}' from database.\")\n",
    "                    try:\n",
    "                        delete_law_metadata_from_db(pcode_to_delete, self.db_conn)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error during DB delete for pcode '{pcode_to_delete}': {e}.\")\n",
    "                else:\n",
    "                    print(f\"Warning: Cannot delete '{law_name_to_remove}' from DB as its PCode ('代號') is missing.\")\n",
    "        else:\n",
    "            print(f\"Law '{law_name_or_short_name}' not found in manager.\")\n",
    "\n",
    "    def find_lm(self, law_name_or_short_name):\n",
    "        law_name_to_find = self.short_names.get(law_name_or_short_name, law_name_or_short_name)\n",
    "        return self.lms.get(law_name_to_find, None)\n",
    "\n",
    "    def load_lm_bynames_from_json(self, short_names_list):\n",
    "        \"\"\"Loads LawMetadata from JSON files based on a list of short names.\"\"\"\n",
    "        loaded_count = 0\n",
    "        for short_name in short_names_list:\n",
    "            base_path = os.path.join(self.dir_json, short_name)\n",
    "            lm = LawMetadata.from_json_files(\n",
    "                f\"{base_path}_law_regulation.json\",\n",
    "                f\"{base_path}_legal_concepts.json\",\n",
    "                f\"{base_path}_hierarchy_relations.json\",\n",
    "                f\"{base_path}_law_relations.json\",\n",
    "                f\"{base_path}_law_articles.json\"\n",
    "            )\n",
    "            if lm:\n",
    "                self.add_lm(lm, short_name)\n",
    "                loaded_count += 1\n",
    "        print(f\"Finished loading from JSON. {loaded_count} laws processed.\")\n",
    "        \n",
    "    def load_lm_from_db(self, law_pcode_to_load: str = None):\n",
    "        \"\"\"Loads LawMetadata from the database for a specific pcode or all laws.\"\"\"\n",
    "        if not self.db_conn:\n",
    "            print(\"Error: Database connection not available for load_lm_from_db.\")\n",
    "            return\n",
    "\n",
    "        laws_query = \"SELECT id AS law_db_id, pcode, xml_law_name, law_metadata FROM laws\" \n",
    "        params = []\n",
    "        if law_pcode_to_load:\n",
    "            laws_query += \" WHERE pcode = %s\"\n",
    "            params.append(law_pcode_to_load)\n",
    "        \n",
    "        base_law_records = fetch_query(self.db_conn, laws_query, tuple(params) if params else None)\n",
    "        if not base_law_records:\n",
    "            print(f\"No laws found in DB for pcode '{law_pcode_to_load if law_pcode_to_load else 'ALL'}'.\")\n",
    "            return\n",
    "\n",
    "        loaded_count = 0\n",
    "        if not law_pcode_to_load:\n",
    "            print(\"Clearing existing in-memory laws before loading all from DB.\")\n",
    "            self.lms.clear()\n",
    "            self.short_names.clear()\n",
    "            \n",
    "        for law_record in base_law_records:\n",
    "            law_db_id, pcode, xml_law_name, law_metadata_json = law_record\n",
    "\n",
    "            law_regulation_data = {}\n",
    "            if law_metadata_json:\n",
    "                law_regulation_data = json.loads(law_metadata_json) if isinstance(law_metadata_json, str) else law_metadata_json\n",
    "            else:\n",
    "                law_regulation_data['法規名稱'] = xml_law_name\n",
    "                law_regulation_data['代號'] = pcode\n",
    "            \n",
    "            current_law_name = law_regulation_data.get('法規名稱', xml_law_name or pcode)\n",
    "            print(f\"Processing law from DB: {current_law_name} (PCode: {pcode}, DB ID: {law_db_id})\")\n",
    "\n",
    "            articles_query = \"SELECT id AS article_db_id, xml_article_number, xml_chapter_section, xml_article_content, article_metadata FROM articles WHERE law_id = %s ORDER BY xml_article_number;\"\n",
    "            article_records = fetch_query(self.db_conn, articles_query, (law_db_id,))\n",
    "            \n",
    "            fetched_articles_list = []\n",
    "            for art_rec in (article_records or []):\n",
    "                article_db_id, xml_article_number, xml_chapter_section, xml_article_content, article_metadata_json = art_rec\n",
    "                article_data = {}\n",
    "                if article_metadata_json:\n",
    "                    article_data = json.loads(article_metadata_json) if isinstance(article_metadata_json, str) else article_metadata_json\n",
    "                else:\n",
    "                    article_data['條號'] = xml_article_number\n",
    "                    article_data['編章節'] = xml_chapter_section\n",
    "                    article_data['條文內容'] = xml_article_content\n",
    "                article_data['db_id'] = article_db_id\n",
    "                fetched_articles_list.append(article_data)\n",
    "\n",
    "            concepts_query = \"SELECT data FROM legal_concepts WHERE law_id = %s;\"\n",
    "            concept_records = fetch_query(self.db_conn, concepts_query, (law_db_id,))\n",
    "            fetched_concepts_list = [json.loads(rec[0]) if isinstance(rec[0], str) else rec[0] for rec in concept_records or [] if rec[0]]\n",
    "\n",
    "            hierarchy_query = \"SELECT data FROM law_hierarchy_relationships WHERE main_law_id = %s OR related_law_id = %s;\"\n",
    "            hierarchy_records = fetch_query(self.db_conn, hierarchy_query, (law_db_id, law_db_id))\n",
    "            fetched_hierarchy_list = [json.loads(rec[0]) if isinstance(rec[0], str) else rec[0] for rec in hierarchy_records or [] if rec[0]]\n",
    "\n",
    "            law_relations_query = \"SELECT data FROM law_relationships WHERE main_law_id = %s OR related_law_id = %s OR main_article_id IN (SELECT id FROM articles WHERE law_id = %s) OR related_article_id IN (SELECT id FROM articles WHERE law_id = %s);\"\n",
    "            law_relation_records = fetch_query(self.db_conn, law_relations_query, (law_db_id, law_db_id, law_db_id, law_db_id))\n",
    "            fetched_law_relations_list = [json.loads(rec[0]) if isinstance(rec[0], str) else rec[0] for rec in law_relation_records or [] if rec[0]]\n",
    "\n",
    "            lm = LawMetadata(\n",
    "                law_regulation=law_regulation_data, \n",
    "                legal_concepts=fetched_concepts_list, \n",
    "                hierarchy_relations=fetched_hierarchy_list, \n",
    "                law_relations=fetched_law_relations_list, \n",
    "                law_articles=fetched_articles_list\n",
    "            )\n",
    "            self.lms[lm.law_name] = lm \n",
    "            self.short_names[lm.law_name] = lm.law_name \n",
    "            print(f\"  Reconstructed and added LawMetadata for '{lm.law_name}' (PCode: {pcode}) to manager.\")\n",
    "            loaded_count += 1\n",
    "        print(f\"Finished loading from DB. {loaded_count} laws processed and added to manager.\")\n",
    "\n",
    "    def export_all_to_json(self):\n",
    "        \"\"\"Exports all LawMetadata objects in the manager to JSON files using their short_name as prefix.\"\"\"\n",
    "        if not os.path.exists(self.dir_json):\n",
    "            os.makedirs(self.dir_json)\n",
    "            print(f\"Created directory: {self.dir_json}\")\n",
    "        \n",
    "        exported_count = 0\n",
    "        for law_name, lm in self.lms.items():\n",
    "            safe_short_name = lm.short_name.replace('/', '_').replace('\\\\', '_')\n",
    "            file_prefix = os.path.join(self.dir_json, safe_short_name)\n",
    "            lm.to_json_files(output_prefix=file_prefix)\n",
    "            exported_count +=1\n",
    "        print(f\"Exported {exported_count} laws to JSON files in '{self.dir_json}' directory.\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"LawMetadataManager(law_count={len(self.lms)}, db_connected={'Yes' if self.db_conn else 'No'})\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the PostgreSQL Database\n",
    "This notebook has been enhanced to support PostgreSQL for persistent storage and management of `LawMetadata` objects. This offers several advantages over using only local JSON files, including:\n",
    "- **Persistent Storage:** Data saved to the database will persist across notebook sessions.\n",
    "- **Structured Querying:** Although the current analysis tools in this notebook are Python-based, storing data in a relational database allows for powerful SQL querying capabilities externally (e.g., for complex data retrieval, reporting, or integration with other systems).\n",
    "- **Data Sharing & Centralization:** A database can serve as a central repository for legal metadata, accessible by multiple users or processes (with appropriate database permissions).\n",
    "\n",
    "**Dual-Mode Capability:**\n",
    "The notebook, particularly the `LawMetadataMgr` class, is designed to operate in a \"dual mode\":\n",
    "1.  **JSON-Only Mode:** If a database connection is not provided to `LawMetadataMgr` during its initialization, it will work exclusively with local JSON files (loading from and saving to the `./json` directory).\n",
    "2.  **Database-Integrated Mode:** If a database connection object is provided, `LawMetadataMgr` methods like `add_lm` and `remove_lm` will automatically attempt to synchronize changes with the database (i.e., upserting or deleting corresponding records).\n",
    "\n",
    "This section provides a comprehensive guide to setting up the database, creating the schema, and performing various operations such as loading data from JSON to the DB, retrieving data from the DB into `LawMetadata` objects, deleting data, and using the analysis tools with DB-loaded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Database Connection and Core Utility Functions\n",
    "This cell defines essential functions for database interaction. It's crucial for any subsequent database operations.\n",
    "\n",
    "**Key Functions Defined Here:**\n",
    "- `get_db_connection()`: Establishes a connection to the PostgreSQL database.\n",
    "  - **Configuration Required:** The connection parameters (`DB_NAME`, `DB_USER`, `DB_PASSWORD`, `DB_HOST`, `DB_PORT`) are defined at the beginning of this code cell. \n",
    "  - **Best Practice:** Set these using environment variables for security and flexibility (e.g., `os.getenv('DB_USER', 'your_default_user')`). \n",
    "  - **Manual Setup:** If not using environment variables, **you must replace the placeholder default values** (like `'your_default_db_name'`) with your actual database credentials and details.\n",
    "  - **Server Accessibility:** Ensure your PostgreSQL server is running and accessible from the environment where this notebook is executed.\n",
    "- `execute_query()`: Executes general SQL commands that modify the database (e.g., INSERT, UPDATE, DELETE, DDL like `CREATE TABLE`). It handles transaction commits and rollbacks.\n",
    "- `fetch_query()`: Executes SELECT queries and fetches results.\n",
    "- `create_db_schema()`: Reads and executes SQL from `law_db_law.sql` to set up the database tables.\n",
    "- Helper ID Lookup Functions (e.g., `_get_law_db_id_by_code`): Internal functions used by the main upsert/delete operations to find database primary keys.\n",
    "- `upsert_law_metadata_to_db()`: A comprehensive function to save or update a `LawMetadata` object and all its constituent parts (regulation, articles, concepts, relations) into the database.\n",
    "- `delete_law_metadata_from_db()`: Deletes a law and all its associated data from the database based on its unique code.\n",
    "\n",
    "**Prerequisites for running this cell and subsequent DB operations:**\n",
    "- `psycopg2-binary` library must be installed (`pip install psycopg2-binary`).\n",
    "- A PostgreSQL server must be running and accessible.\n",
    "- Database connection parameters below must be correctly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install psycopg2-binary if you haven't: pip install psycopg2-binary\n",
    "import psycopg2\n",
    "import os\n",
    "import json # Ensure json is imported here for json.dumps\n",
    "\n",
    "# --- Database Connection Parameters --- \n",
    "# IMPORTANT: Configure these for your PostgreSQL instance.\n",
    "# Using environment variables is recommended for sensitive data like passwords.\n",
    "# Example: os.getenv('DB_NAME', 'your_default_db_name')\n",
    "# If not using environment variables, replace the default string values directly.\n",
    "DB_NAME = os.getenv('DB_NAME', 'your_default_db_name')         # Your database name\n",
    "DB_USER = os.getenv('DB_USER', 'your_default_user')           # Your PostgreSQL username\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD', 'your_default_password') # Your PostgreSQL password\n",
    "DB_HOST = os.getenv('DB_HOST', 'localhost')                   # Database host (e.g., 'localhost' or an IP address)\n",
    "DB_PORT = os.getenv('DB_PORT', '5432')                      # Database port (default for PostgreSQL is '5432')\n",
    "# Ensure the PostgreSQL server is running and accessible with these credentials.\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Establishes a connection to the PostgreSQL database.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT\n",
    "        )\n",
    "        print(\"Successfully connected to PostgreSQL.\")\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to PostgreSQL: {e}\")\n",
    "        return None\n",
    "\n",
    "def execute_query(conn, query, params=None):\n",
    "    \"\"\"\n",
    "    Executes a query that modifies the database (INSERT, UPDATE, DELETE).\n",
    "    Also handles execution of multi-statement SQL scripts.\n",
    "    \n",
    "    Args:\n",
    "        conn: Active database connection.\n",
    "        query (str): SQL query string or script.\n",
    "        params (tuple, optional): Parameters for the query. Not typically used for multi-statement scripts.\n",
    "    \"\"\"\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query, params)\n",
    "        conn.commit()\n",
    "        # print(\"Query executed successfully.\") # Making this less verbose for batch operations\n",
    "    except psycopg2.Error as e:\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        # raise  # Optionally re-raise the exception\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "\n",
    "def fetch_query(conn, query, params=None):\n",
    "    \"\"\"\n",
    "    Executes a query and fetches results (SELECT).\n",
    "    \n",
    "    Args:\n",
    "        conn: Active database connection.\n",
    "        query (str): SQL query string.\n",
    "        params (tuple, optional): Parameters for the query. Defaults to None.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples representing the fetched rows, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query, params)\n",
    "        results = cursor.fetchall()\n",
    "        return results\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error fetching query: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "\n",
    "def create_db_schema(conn):\n",
    "    \"\"\"\n",
    "    Reads SQL statements from 'law_meta_db_v0.2.sql' and executes them to create the DB schema.\n",
    "\n",
    "    Args:\n",
    "        conn: Active database connection.\n",
    "    \"\"\"\n",
    "    if 1:\n",
    "        return\n",
    "    try:\n",
    "        with open('law_meta_db_v0.2.sql', 'r', encoding='utf-8') as f:\n",
    "            sql_script = f.read()\n",
    "        \n",
    "        print(\"Attempting to create database schema from law_meta_db_v0.2.sql...\")\n",
    "        execute_query(conn, sql_script) \n",
    "        print(\"Database schema creation process completed.\")\n",
    "        print(\"Please check for any errors above from execute_query. If 'Query executed successfully.' was printed by execute_query, the script likely ran.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: law_meta_db_v0.2.sql not found. Cannot create database schema.\")\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error during schema creation: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "\n",
    "### --- Helper functions for DB ID lookups --- \n",
    "def _get_law_pcode_by_name(law_name, conn):\n",
    "    \"\"\"Fetches the pcode of a law by its name (xml_law_name).\"\"\"\n",
    "    if not law_name: return None\n",
    "    query = \"SELECT pcode FROM laws WHERE xml_law_name = %s;\"\n",
    "    result = fetch_query(conn, query, (law_name,))\n",
    "    return result[0][0] if result else None\n",
    "\n",
    "def _get_law_db_id_by_pcode(pcode, conn):\n",
    "    \"\"\"Fetches the database ID of a law by its pcode.\"\"\"\n",
    "    if not pcode: return None\n",
    "    query = \"SELECT id FROM laws WHERE pcode = %s;\"\n",
    "    result = fetch_query(conn, query, (pcode,))\n",
    "    return result[0][0] if result else None\n",
    "\n",
    "def chinese_to_arabic(cn_str):\n",
    "    \"\"\"\n",
    "    A simple converter for Chinese numeral strings found in law article numbers.\n",
    "    Handles numbers up to 9999.\n",
    "    e.g., \"四\" -> 4, \"二十一\" -> 21, \"一百二十一\" -> 121\n",
    "    \"\"\"\n",
    "    if not isinstance(cn_str, str):\n",
    "        return None\n",
    "\n",
    "    # If it's already arabic, just return it as int\n",
    "    if cn_str.isdigit():\n",
    "        try:\n",
    "            return int(cn_str)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    cn_map = {'零': 0, '一': 1, '二': 2, '三': 3, '四': 4, '五': 5, '六': 6, '七': 7, '八': 8, '九': 9}\n",
    "    unit_map = {'十': 10, '百': 100, '千': 1000}\n",
    "    \n",
    "    cn_str = cn_str.strip()\n",
    "    # Handle \"十\" at the beginning, e.g., \"十\" -> 10, \"十一\" -> 11\n",
    "    if cn_str.startswith('十'):\n",
    "        cn_str = '一' + cn_str\n",
    "\n",
    "    total = 0\n",
    "    temp_num = 0\n",
    "    for char in cn_str:\n",
    "        if char in cn_map:\n",
    "            temp_num = cn_map[char]\n",
    "        elif char in unit_map:\n",
    "            if temp_num == 0:\n",
    "                temp_num = 1\n",
    "            total += temp_num * unit_map[char]\n",
    "            temp_num = 0\n",
    "        else:\n",
    "            return None # Invalid character\n",
    "    total += temp_num\n",
    "    return total\n",
    "\n",
    "   \n",
    "\n",
    "def normalize_article_number(article_str):\n",
    "    \"\"\"\n",
    "    Converts an article number string (e.g., \"第四條\", \"第 4 條\", \"第4條之1\", \"第三條之一\")\n",
    "    into a canonical format (e.g., \"第 4 條\", \"第 4-1 條\", \"第 3-1 條\").\n",
    "    \"\"\"\n",
    "    if not article_str:\n",
    "        return None\n",
    "    \n",
    "    s = article_str.strip().replace(' ', '')\n",
    "    s = s.replace('条', '條') \n",
    "    \n",
    "    # Handle sub-articles like \"之\"\n",
    "    parts = s.split('之')\n",
    "    \n",
    "    arabic_parts = []\n",
    "    for part in parts:\n",
    "        # clean up each part\n",
    "        p = part\n",
    "        if p.startswith('第'):\n",
    "            p = p[1:]\n",
    "        if p.endswith('條'):\n",
    "            p = p[:-1]\n",
    "            \n",
    "        # Convert Chinese part to Arabic\n",
    "        arabic_val = chinese_to_arabic(p)\n",
    "        if arabic_val is not None:\n",
    "            arabic_parts.append(str(arabic_val))\n",
    "        else:\n",
    "            # Could not convert, maybe it's already mixed or invalid.\n",
    "            # Fallback to original part, but cleaned.\n",
    "            arabic_parts.append(p)\n",
    "            \n",
    "    numeric_part = \"-\".join(arabic_parts)\n",
    "    return f\"第 {numeric_part} 條\"\n",
    "\n",
    "def _get_article_db_id_by_law_db_id_and_article_number(law_db_id, article_number, conn):\n",
    "    \"\"\"\n",
    "    Fetches the database ID of an article by its law_db_id and article_number.\n",
    "    This version handles conversion between Chinese and Arabic numerals and varying whitespace\n",
    "    by fetching all articles for the law and normalizing them in Python.\n",
    "    Note: This is more robust but less efficient if called in a loop for the same law,\n",
    "    as it fetches all articles for that law on each call.\n",
    "    \"\"\"\n",
    "    if not law_db_id or not article_number:\n",
    "        return None\n",
    "\n",
    "    # 1. Normalize the target article number from the JSON\n",
    "    normalized_target = normalize_article_number(article_number)\n",
    "    if not normalized_target:\n",
    "        return None\n",
    "\n",
    "    # 2. Fetch all articles for the given law_db_id\n",
    "    query = \"SELECT id, xml_article_number FROM articles WHERE law_id = %s;\"\n",
    "    records = fetch_query(conn, query, (law_db_id,))\n",
    "    if not records:\n",
    "        return None\n",
    "\n",
    "    # 3. Normalize each article number from the DB and find a match\n",
    "    for db_id, db_article_number in records:\n",
    "        if db_article_number:\n",
    "            normalized_db_num = normalize_article_number(db_article_number)\n",
    "            if normalized_db_num == normalized_target:\n",
    "                return db_id\n",
    "            \n",
    "    return None\n",
    "\n",
    "def _get_concept_db_id_by_code(concept_code, conn):\n",
    "    \"\"\"Fetches the database ID of a legal concept by its code.\"\"\"\n",
    "    if not concept_code: return None\n",
    "    query = \"SELECT id FROM legal_concepts WHERE code = %s;\"\n",
    "    result = fetch_query(conn, query, (concept_code,))\n",
    "    return result[0][0] if result else None\n",
    "\n",
    "### --- Main DB Upsert/Delete Functions --- \n",
    "def delete_law_metadata_from_db(pcode: str, conn):\n",
    "    \"\"\"Deletes a law and its related data from the database based on pcode.\"\"\"\n",
    "    if not pcode:\n",
    "        print(\"Error: Law pcode cannot be empty for deletion.\")\n",
    "        return False\n",
    "    print(f\"Attempting to delete law with pcode: {pcode} and its related data...\")\n",
    "    # ON DELETE CASCADE in the schema will handle deletion of related data in other tables.\n",
    "    query = \"DELETE FROM laws WHERE pcode = %s;\"\n",
    "    execute_query(conn, query, (pcode,))\n",
    "    print(f\"Deletion process for law pcode {pcode} initiated.\")\n",
    "    return True\n",
    "\n",
    "def upsert_law_metadata_to_db(lm: LawMetadata, conn):\n",
    "    \"\"\"\n",
    "    Upserts a LawMetadata object into the database.\n",
    "    This version focuses on updating metadata for existing laws and articles.\n",
    "    - It updates the law's metadata (in 'laws' table) and each article's metadata (in 'articles' table).\n",
    "    - It does NOT create or delete article records, assuming they are managed by another process (e.g., law_proc.ipynb).\n",
    "    - It performs a \"clean and refresh\" for associated metadata: concepts are upserted, and all relationships \n",
    "      (law-to-law, law-to-article, article-to-concept) for the law are deleted and re-inserted from the LawMetadata object.\n",
    "    \"\"\"\n",
    "    law_name = lm.law_regulation.get('法規名稱')\n",
    "    if not law_name:\n",
    "        print(\"Error: Law '法規名稱' is missing from law_regulation. Cannot upsert.\")\n",
    "        return False\n",
    "\n",
    "    # 1. Verify law exists and get its pcode and db_id\n",
    "    pcode = _get_law_pcode_by_name(law_name, conn)\n",
    "    if not pcode:\n",
    "        print(f\"Error: Law with name '{law_name}' not found in the database. Upsert aborted. Please ensure the base law record exists.\")\n",
    "        return False\n",
    "    \n",
    "    law_db_id = _get_law_db_id_by_pcode(pcode, conn)\n",
    "    if not law_db_id:\n",
    "        print(f\"Error: Law with pcode '{pcode}' found but could not retrieve its database ID. Aborting.\")\n",
    "        return False\n",
    "\n",
    "    # Update the in-memory object with the correct pcode from the DB\n",
    "    lm.law_regulation['代號'] = pcode\n",
    "    \n",
    "    print(f\"Starting upsert process for law: {law_name} (PCode: {pcode}, DB ID: {law_db_id})\")\n",
    "\n",
    "    try:\n",
    "        # 2. Clean up old metadata relationships for this law before inserting new data\n",
    "        print(f\"  Cleaning up existing relationships for law ID: {law_db_id}...\")\n",
    "        \n",
    "        # Clean up article-to-concept links for the entire law\n",
    "        execute_query(conn, \"DELETE FROM article_legal_concept WHERE article_id IN (SELECT id FROM articles WHERE law_id = %s);\", (law_db_id,))\n",
    "        \n",
    "        # Clean up law_relationships involving this law (law-law, and any links to its articles)\n",
    "        execute_query(conn, \"\"\"\n",
    "            DELETE FROM law_relationships \n",
    "            WHERE (main_law_id = %s) OR (related_law_id = %s)\n",
    "        \"\"\", (law_db_id, law_db_id))\n",
    "\n",
    "        # Clean up law-to-law hierarchy relationships\n",
    "        execute_query(conn, \"DELETE FROM law_hierarchy_relationships WHERE main_law_id = %s OR related_law_id = %s;\", (law_db_id, law_db_id))\n",
    "        \n",
    "        print(\"  Cleanup of relationships complete.\")\n",
    "\n",
    "        # 3. Update the main law record with the new metadata JSON\n",
    "        law_metadata_json = json.dumps(lm.law_regulation)\n",
    "        law_update_query = \"UPDATE laws SET law_metadata = %s WHERE id = %s;\"\n",
    "        execute_query(conn, law_update_query, (law_metadata_json, law_db_id))\n",
    "        print(f\"  Updated 'law_metadata' in 'laws' table for ID: {law_db_id}\")\n",
    "\n",
    "        concept_code_to_db_id_map = {}\n",
    "\n",
    "        # 4. Update article metadata (DO NOT INSERT/DELETE ARTICLES)\n",
    "        print(f\"  Updating article metadata...\")\n",
    "        updated_article_count = 0\n",
    "        for article in lm.law_articles:\n",
    "            article_number = article.get('條號')\n",
    "            if not article_number:\n",
    "                print(\"  Warning: Skipping article in JSON with missing '條號'.\")\n",
    "                continue\n",
    "\n",
    "            # Find article_db_id using flexible helper\n",
    "            article_db_id = _get_article_db_id_by_law_db_id_and_article_number(law_db_id, article_number, conn)\n",
    "\n",
    "            if article_db_id:\n",
    "                article_metadata_json = json.dumps(article)\n",
    "                article_update_query = \"UPDATE articles SET article_metadata = %s WHERE id = %s;\"\n",
    "                execute_query(conn, article_update_query, (article_metadata_json, article_db_id))\n",
    "                article['db_id'] = article_db_id  # Store db_id in the in-memory object for later steps\n",
    "                updated_article_count += 1\n",
    "            else:\n",
    "                print(f\"  Warning: Article '{article_number}->{article_db_id}' not found in DB for law '{law_name}'. Cannot update its metadata or link concepts/relationships.\")\n",
    "        print(f\"  Finished updating metadata for {updated_article_count} articles.\")\n",
    "\n",
    "\n",
    "        # 5. Upsert legal concepts (shared table)\n",
    "        for concept in lm.legal_concepts:\n",
    "            concept_code = concept.get('代號')\n",
    "            concept_name = concept.get('詞彙名稱')\n",
    "            concept_data_json = json.dumps(concept)\n",
    "            concept_upsert_query = \"\"\"\n",
    "            INSERT INTO legal_concepts (law_id, code, name, data) \n",
    "            VALUES (%s, %s, %s, %s) \n",
    "            ON CONFLICT (code) DO UPDATE SET name = EXCLUDED.name, data = EXCLUDED.data, law_id = EXCLUDED.law_id\n",
    "            RETURNING id;\n",
    "            \"\"\"\n",
    "            concept_id_result = fetch_query(conn, concept_upsert_query, (law_db_id, concept_code, concept_name, concept_data_json))\n",
    "            if concept_id_result and concept_id_result[0]:\n",
    "                concept['db_id'] = concept_id_result[0][0]\n",
    "                concept_code_to_db_id_map[concept_code] = concept['db_id']\n",
    "            else:\n",
    "                print(f\"  Warning: Failed to upsert legal_concept {concept_code}.\")\n",
    "\n",
    "        # 6. Insert new law hierarchy relationships\n",
    "        for relation in lm.hierarchy_relations:\n",
    "            rel_code = relation.get('關係代號')\n",
    "            main_law_name_hier = relation.get('主法規')\n",
    "            related_law_name_hier = relation.get('關聯法規')\n",
    "            \n",
    "            main_law_pcode_hier = _get_law_pcode_by_name(main_law_name_hier, conn)\n",
    "            related_law_pcode_hier = _get_law_pcode_by_name(related_law_name_hier, conn)\n",
    "\n",
    "            hierarchy_type = relation.get('階層關係類型')\n",
    "            relation_data_json = json.dumps(relation)\n",
    "            \n",
    "            main_law_db_id_hier = _get_law_db_id_by_pcode(main_law_pcode_hier, conn)\n",
    "            related_law_db_id_hier = _get_law_db_id_by_pcode(related_law_pcode_hier, conn)\n",
    "\n",
    "            if main_law_db_id_hier and related_law_db_id_hier and rel_code:\n",
    "                hier_insert_query = \"\"\"\n",
    "                INSERT INTO law_hierarchy_relationships \n",
    "                    (relationship_code, main_law_id, related_law_id, hierarchy_type, data)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (relationship_code) DO NOTHING;\n",
    "                \"\"\"\n",
    "                execute_query(conn, hier_insert_query, (rel_code, main_law_db_id_hier, related_law_db_id_hier, hierarchy_type, relation_data_json))\n",
    "            else:\n",
    "                print(f\"  Warning: Skipping law_hierarchy_relationship for {rel_code} due to missing law pcode/IDs or relation code. Main Law: '{main_law_name_hier}' (found pcode: {main_law_pcode_hier}), Related Law: '{related_law_name_hier}' (found pcode: {related_law_pcode_hier}).\")\n",
    "\n",
    "        # 7. Insert new law relationships\n",
    "        for relation in lm.law_relations:\n",
    "            rel_code = relation.get('代號')\n",
    "            main_law_pcode_rel = relation.get('主法規代號')\n",
    "            main_article_num_rel = relation.get('主法條條號')\n",
    "            related_law_pcode_rel = relation.get('關聯法規代號')\n",
    "            related_article_num_rel = relation.get('關聯法條條號')\n",
    "            relationship_type = relation.get('關聯類型', relation.get('relationship_type'))\n",
    "            relation_data_json = json.dumps(relation)\n",
    "            \n",
    "            main_law_db_id_rel = _get_law_db_id_by_pcode(main_law_pcode_rel, conn)\n",
    "            related_law_db_id_rel = _get_law_db_id_by_pcode(related_law_pcode_rel, conn)\n",
    "            \n",
    "            main_article_db_id_rel = None\n",
    "            if main_law_db_id_rel and main_article_num_rel:\n",
    "                main_article_db_id_rel = _get_article_db_id_by_law_db_id_and_article_number(main_law_db_id_rel, main_article_num_rel, conn)\n",
    "            \n",
    "            related_article_db_id_rel = None\n",
    "            if related_law_db_id_rel and related_article_num_rel:\n",
    "                related_article_db_id_rel = _get_article_db_id_by_law_db_id_and_article_number(related_law_db_id_rel, related_article_num_rel, conn)\n",
    "            \n",
    "            if rel_code and relationship_type:\n",
    "                law_rel_insert_query = \"\"\"\n",
    "                INSERT INTO law_relationships \n",
    "                    (code, relationship_type, main_law_id, main_article_id, related_law_id, related_article_id, data)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (code) DO NOTHING;\n",
    "                \"\"\"\n",
    "                execute_query(conn, law_rel_insert_query, (\n",
    "                    rel_code, relationship_type, \n",
    "                    main_law_db_id_rel, main_article_db_id_rel,\n",
    "                    related_law_db_id_rel, related_article_db_id_rel,\n",
    "                    relation_data_json\n",
    "                ))\n",
    "            else:\n",
    "                print(f\"  Warning: Skipping law_relationship for {rel_code} due to missing code or type.\")\n",
    "\n",
    "        # 8. Populate article_legal_concept table\n",
    "        for article in lm.law_articles:\n",
    "            article_db_id = article.get('db_id') # This now depends on the successful update in step 4\n",
    "            if not article_db_id:\n",
    "                continue\n",
    "            related_concept_codes = article.get('相關概念代號列表', [])\n",
    "            for concept_code in related_concept_codes:\n",
    "                concept_db_id = concept_code_to_db_id_map.get(concept_code)\n",
    "                if concept_db_id:\n",
    "                    alc_insert_query = \"\"\"\n",
    "                    INSERT INTO article_legal_concept (article_id, legal_concept_id)\n",
    "                    VALUES (%s, %s) ON CONFLICT DO NOTHING;\n",
    "                    \"\"\"\n",
    "                    execute_query(conn, alc_insert_query, (article_db_id, concept_db_id))\n",
    "                else:\n",
    "                    print(f\"    Warning: Concept DB ID not found for code {concept_code} when linking to article {article.get('條號')}.\")\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"Upsert process for law pcode {pcode} completed successfully.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An overall error occurred during upsert_law_metadata_to_db for {pcode}: {e}\")\n",
    "        if conn: conn.rollback()\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Creating the Database Schema\n",
    "This step is crucial and should be performed once to set up the necessary tables in your PostgreSQL database. It executes the SQL commands defined in `law_db_law.sql`.\n",
    "**Prerequisite:**\n",
    "- Database connection parameters must be correctly set in the utility cell above.\n",
    "- The `law_db_law.sql` file must be present in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- B. Creating Database Schema ---\")\n",
    "conn_schema = get_db_connection()\n",
    "if conn_schema:\n",
    "    try:\n",
    "        if 0:\n",
    "            create_db_schema(conn_schema)\n",
    "    finally:\n",
    "        conn_schema.close()\n",
    "        print(\"DB connection for schema creation closed.\")\n",
    "else:\n",
    "    print(\"Failed to connect to the database. Schema creation skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Loading JSON Data and Upserting to Database\n",
    "This section demonstrates how to load `LawMetadata` from JSON files and then save it to the database.\n",
    "\n",
    "#### C.ii. Upserting Multiple `LawMetadata` Objects via `LawMetadataMgr` (from JSON files to DB)\n",
    "This demonstrates using `LawMetadataMgr` to load multiple laws from JSON files. If the manager is initialized with a database connection, laws are automatically upserted to the DB when added to the manager via `add_lm` (which is called by `load_lm_bynames_from_json`).\n",
    "**Prerequisites:**\n",
    "- JSON files for the specified laws (e.g., \"政府採購法\", \"民法\") must exist.\n",
    "- Database schema must be created.\n",
    "\n",
    "#### Issues\n",
    "- 目前有的 json 約需跑 20 分鐘，還有些 warning, error 需要 fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- C.ii. Upserting Multiple Laws via LawMetadataMgr (JSON to DB) ---\")\n",
    "\n",
    "# This cell uses LawMetadataMgr to load laws from JSON and upsert them to the DB.\n",
    "# It supports multiple modes for selecting which laws to process.\n",
    "# The logic correctly uses the file's \"short name\" to locate JSON files,\n",
    "# and then uses the true \"法規名稱\" from the JSON content for all database interactions.\n",
    "\n",
    "# --- Configuration for Upsert ---\n",
    "# Set the desired upsert mode. Options are:\n",
    "# \"single\": Upsert one specific law defined in `law_to_upsert_single`.\n",
    "# \"multiple\": Upsert a list of laws defined in `laws_to_upsert_multiple`.\n",
    "# \"all_from_json\": Upsert all laws that have corresponding JSON files in the `dir_json` directory.\n",
    "upsert_mode = \"single\"  # <-- CHANGE THIS to \"single\" or \"multiple\", \"all_from_json\" as needed\n",
    "\n",
    "# --- Define laws to be upserted based on their short name (filename) ---\n",
    "law_to_upsert_single = \"預算法\"  # Used when upsert_mode is \"single\"\n",
    "laws_to_upsert_multiple = [\"政府採購法\", \"民法\"]  # Used when upsert_mode is \"multiple\"\n",
    "\n",
    "# --- Main Upsert Logic ---\n",
    "available_json_laws = get_law_names_from_directory(dir_json)\n",
    "print(f\"Available JSON laws (by short name) in '{dir_json}': {available_json_laws}\")\n",
    "\n",
    "short_names_to_upsert = []\n",
    "if upsert_mode == \"single\":\n",
    "    if law_to_upsert_single and law_to_upsert_single in available_json_laws:\n",
    "        short_names_to_upsert.append(law_to_upsert_single)\n",
    "    elif not law_to_upsert_single:\n",
    "         print(\"Warning: Upsert mode is 'single' but no law name is specified in 'law_to_upsert_single'.\")\n",
    "    else:\n",
    "         print(f\"Warning: Law '{law_to_upsert_single}' not found in available JSON files.\")\n",
    "elif upsert_mode == \"multiple\":\n",
    "    short_names_to_upsert.extend([name for name in laws_to_upsert_multiple if name in available_json_laws])\n",
    "    if len(short_names_to_upsert) != len(laws_to_upsert_multiple):\n",
    "        print(f\"Warning: Some laws in 'laws_to_upsert_multiple' were not found in the available JSON files.\")\n",
    "elif upsert_mode == \"all_from_json\":\n",
    "    short_names_to_upsert.extend(available_json_laws)\n",
    "    print(f\"Found {len(available_json_laws)} laws to potentially upsert from the JSON directory.\")\n",
    "else:\n",
    "    print(f\"Error: Invalid upsert_mode '{upsert_mode}'. Please choose 'single', 'multiple', or 'all_from_json'.\")\n",
    "\n",
    "if not short_names_to_upsert:\n",
    "    print(\"No laws to upsert. Exiting.\")\n",
    "else:\n",
    "    print(f\"Will attempt to load and upsert the following laws (by short name): {short_names_to_upsert}\")\n",
    "    conn_mgr_upsert = get_db_connection()\n",
    "    if conn_mgr_upsert:\n",
    "        # Initialize the manager with the DB connection.\n",
    "        lmmgr_for_multi_upsert = LawMetadataMgr(db_conn=conn_mgr_upsert)\n",
    "        try:\n",
    "            # This method iterates through the short names, loads the corresponding files,\n",
    "            # creates LawMetadata objects (which contain the *real* law name), and then\n",
    "            # the manager's add_lm method calls the upsert function for each.\n",
    "            lmmgr_for_multi_upsert.load_lm_bynames_from_json(short_names_to_upsert)\n",
    "            \n",
    "            print(f\"\\n--- Multi-Upsert Summary ---\")\n",
    "            print(f\"Finished processing {len(short_names_to_upsert)} laws for upsert via LawMetadataMgr.\")\n",
    "            print(f\"Laws now in manager (by real name): {list(lmmgr_for_multi_upsert.lms.keys())}\")\n",
    "        except Exception as e_mgr_upsert:\n",
    "            print(f\"An error occurred during multi-upsert via LawMetadataMgr: {e_mgr_upsert}\")\n",
    "        finally:\n",
    "            conn_mgr_upsert.close()\n",
    "            print(\"\\nDB connection for multi-upsert via LawMetadataMgr closed.\")\n",
    "    else:\n",
    "        print(\"Failed to connect to DB for multi-law upsert via LawMetadataMgr.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Loading `LawMetadata` from Database using `LawMetadataMgr`\n",
    "These examples show how to use `LawMetadataMgr` (initialized with a database connection) to load `LawMetadata` objects directly from the PostgreSQL database. When `LawMetadataMgr` is initialized with a `db_conn`, its methods `add_lm` and `remove_lm` interact with the database. The `load_lm_from_db` method specifically fetches data from the database to populate the manager's in-memory collection.\n",
    "**Prerequisites:**\n",
    "- Database schema must be created (Section B).\n",
    "- Data for the laws to be loaded must exist in the database (e.g., from Section C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- D.i. Loading a Specific Law from DB into LawMetadataMgr ---\")\n",
    "conn_load_single_db = get_db_connection()\n",
    "if conn_load_single_db:\n",
    "    lmmgr_load_single = LawMetadataMgr(db_conn=conn_load_single_db)\n",
    "    try:\n",
    "        law_code_to_load_specific = example_law_code_for_later_use if 'example_law_code_for_later_use' in locals() and example_law_code_for_later_use else \"LT_政府採購法\"\n",
    "        law_name_to_find_specific = example_law_name_for_later_use if 'example_law_name_for_later_use' in locals() and example_law_name_for_later_use else \"政府採購法\"\n",
    "\n",
    "        print(f\"Attempting to load law with code '{law_code_to_load_specific}' from DB...\")\n",
    "        lmmgr_load_single.load_lm_from_db(law_pcode_to_load=law_code_to_load_specific) #param name updated for clarity\n",
    "        \n",
    "        loaded_lm_specific = lmmgr_load_single.find_lm(law_name_to_find_specific)\n",
    "        if loaded_lm_specific:\n",
    "            print(f\"Successfully loaded and found '{loaded_lm_specific.law_name}' (Code: {loaded_lm_specific.law_regulation.get('代號')}) from DB.\")\n",
    "            print(f\"  Number of articles: {len(loaded_lm_specific.law_articles)}\")\n",
    "            print(f\"  Number of concepts: {len(loaded_lm_specific.legal_concepts)}\")\n",
    "        else:\n",
    "            print(f\"Could not find law with name '{law_name_to_find_specific}' (tried code '{law_code_to_load_specific}') in manager after DB load attempt.\")\n",
    "    finally:\n",
    "        conn_load_single_db.close()\n",
    "        print(\"DB connection for loading single law closed.\")\n",
    "else:\n",
    "    print(\"Failed to connect to DB for loading a single law.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- D.ii. Loading All Laws from DB into LawMetadataMgr ---\")\n",
    "conn_load_all_db = get_db_connection()\n",
    "if conn_load_all_db:\n",
    "    lmmgr_load_all = LawMetadataMgr(db_conn=conn_load_all_db)\n",
    "    try:\n",
    "        print(\"Attempting to load ALL laws from DB...\")\n",
    "        lmmgr_load_all.load_lm_from_db() # Load all\n",
    "        print(f\"Total laws in manager after loading all from DB: {len(lmmgr_load_all.lms)}\")\n",
    "        if lmmgr_load_all.lms:\n",
    "            print(\"Listing loaded laws:\")\n",
    "            for law_obj_name in lmmgr_load_all.lms.keys():\n",
    "                print(f\"- {law_obj_name}\")\n",
    "        else:\n",
    "            print(\"No laws were loaded from the database.\")\n",
    "    finally:\n",
    "        conn_load_all_db.close()\n",
    "        print(\"DB connection for loading all laws closed.\")\n",
    "else:\n",
    "    print(\"Failed to connect to DB for loading all laws.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Deleting `LawMetadata` from Database\n",
    "This demonstrates how to delete a specific law and its associated data from the database using the standalone `delete_law_metadata_from_db` function. Deletion can also occur via `LawMetadataMgr.remove_lm()` if the manager is DB-connected.\n",
    "**Prerequisites:**\n",
    "- The law to be deleted must exist in the database.\n",
    "- The `law_code` for the law must be known (e.g., from a previous upsert operation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- E. Deleting Law(s) from DB ---\")\n",
    "\n",
    "# --- Configuration for Deletion ---\n",
    "# Set the desired deletion mode. Options are:\n",
    "# \"single\": Delete one specific law defined in `law_to_delete_single`.\n",
    "# \"multiple\": Delete a list of laws defined in `laws_to_delete_multiple`.\n",
    "# \"all_from_json\": Delete all laws that have corresponding JSON files in the `dir_json` directory.\n",
    "delete_mode = \"multiple\" # <-- CHANGE THIS to \"multiple\" or \"all_from_json\" as needed\n",
    "\n",
    "# --- Define laws to be deleted based on their short name (filename) ---\n",
    "law_to_delete_single = \"憲法增修合併\" # Used when delete_mode is \"single\"\n",
    "laws_to_delete_multiple = ['憲法合併', '憲法增修合併', '刑法'] # Used when delete_mode is \"multiple\"\n",
    "\n",
    "\n",
    "# --- Main Deletion Logic ---\n",
    "conn_delete = get_db_connection()\n",
    "if conn_delete:\n",
    "    try:\n",
    "        short_names_to_delete = []\n",
    "        if delete_mode == \"single\":\n",
    "            if law_to_delete_single:\n",
    "                short_names_to_delete.append(law_to_delete_single)\n",
    "            else:\n",
    "                print(\"Warning: Delete mode is 'single' but no law name is specified in 'law_to_delete_single'.\")\n",
    "        elif delete_mode == \"multiple\":\n",
    "            short_names_to_delete.extend(laws_to_delete_multiple)\n",
    "        elif delete_mode == \"all_from_json\":\n",
    "            print(f\"Getting all law names from directory: {dir_json}\")\n",
    "            json_law_names = get_law_names_from_directory(dir_json)\n",
    "            short_names_to_delete.extend(json_law_names)\n",
    "            print(f\"Found {len(json_law_names)} laws to potentially delete.\")\n",
    "        else:\n",
    "            print(f\"Error: Invalid delete_mode '{delete_mode}'. Please choose 'single', 'multiple', or 'all_from_json'.\")\n",
    "\n",
    "        if not short_names_to_delete:\n",
    "            print(\"No laws to delete. Exiting.\")\n",
    "        else:\n",
    "            print(f\"Attempting to delete the following laws (by short name): {short_names_to_delete}\")\n",
    "            deleted_count = 0\n",
    "            not_found_count = 0\n",
    "            for short_name in short_names_to_delete:\n",
    "                print(f\"--- Processing '{short_name}' for deletion ---\")\n",
    "                \n",
    "                # First, read the regulation file to get the REAL law name.\n",
    "                reg_filepath = os.path.join(dir_json, f\"{short_name}_law_regulation.json\")\n",
    "                reg_data = load_json_data(reg_filepath)\n",
    "\n",
    "                if not reg_data:\n",
    "                    print(f\"  Warning: Could not find or load '{reg_filepath}'. Cannot determine real law name. Skipping.\")\n",
    "                    not_found_count += 1\n",
    "                    continue\n",
    "                \n",
    "                real_law_name = reg_data.get(\"法規名稱\")\n",
    "                if not real_law_name:\n",
    "                    print(f\"  Warning: '法規名稱' key not found in '{reg_filepath}'. Skipping.\")\n",
    "                    not_found_count += 1\n",
    "                    continue\n",
    "\n",
    "                # Find the pcode for the law using its REAL name.\n",
    "                print(f\"  Real name is '{real_law_name}'. Finding its pcode in the database...\")\n",
    "                pcode_to_delete = _get_law_pcode_by_name(real_law_name, conn_delete)\n",
    "\n",
    "                if pcode_to_delete:\n",
    "                    print(f\"  Found pcode '{pcode_to_delete}'. Proceeding with deletion.\")\n",
    "                    # The delete function uses pcode, and ON DELETE CASCADE in the DB handles the rest.\n",
    "                    success = delete_law_metadata_from_db(pcode_to_delete, conn_delete)\n",
    "                    if success:\n",
    "                        deleted_count += 1\n",
    "                else:\n",
    "                    print(f\"  Warning: Law with real name '{real_law_name}' not found in the database. Cannot delete.\")\n",
    "                    not_found_count += 1\n",
    "            \n",
    "            print(\"\\n--- Deletion Summary ---\")\n",
    "            print(f\"Successfully deleted: {deleted_count} law(s).\")\n",
    "            print(f\"Skipped (not found or file error): {not_found_count} law(s).\")\n",
    "\n",
    "    finally:\n",
    "        conn_delete.close()\n",
    "        print(\"\\nDB connection for deletion closed.\")\n",
    "else:\n",
    "    print(\"Failed to connect to the database. Deletion skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 進階搜尋與分析 (Analysis Tools)\n",
    "This section defines and demonstrates various analysis tools that can operate on `LawMetadata` objects, whether they are loaded from JSON files or from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis function definitions (keyword_search, category_filter, etc.)\n",
    "def keyword_search(metadata, keyword, fields_to_search):\n",
    "    \"\"\"\n",
    "    在指定的 MetaData 欄位中搜尋關鍵字。\n",
    "    Args:\n",
    "        metadata (LawMetaData): LawMetaData 物件。\n",
    "        keyword (str): 要搜尋的關鍵字。\n",
    "        fields_to_search (list of str): 要搜尋的欄位名稱列表 (例如 ['簡述', '定義'])。\n",
    "    Returns:\n",
    "        list: 包含符合條件的 MetaData 物件 (或其子物件)。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    if not metadata: return results # Guard against None metadata\n",
    "    if \"簡述\" in fields_to_search and hasattr(metadata, 'law_regulation') and metadata.law_regulation:\n",
    "        if keyword.lower() in metadata.law_regulation.get(\"簡述\", \"\").lower():\n",
    "            results.append(metadata.law_regulation)\n",
    "    if \"定義\" in fields_to_search and hasattr(metadata, 'legal_concepts') and metadata.legal_concepts:\n",
    "        for concept in metadata.legal_concepts:\n",
    "            if keyword.lower() in concept.get(\"定義\", \"\").lower():\n",
    "                results.append(concept)\n",
    "    return results\n",
    "\n",
    "def category_filter(metadata, category_type, metadata_type=\"hierarchy_relations\"):\n",
    "    \"\"\"\n",
    "    篩選特定類型的 MetaData。\n",
    "    Args:\n",
    "        metadata (LawMetaData): LawMetaData 物件。\n",
    "        category_type (str or Enum): 要篩選的類別/類型 (例如 \"子法規\", ConceptCategory.CORE_CONCEPT_DEFINITION)。\n",
    "        metadata_type (str, optional): 要篩選的 MetaData 類型 (預設為 \"hierarchy_relations\")。\n",
    "    Returns:\n",
    "        list: 符合類別/類型的 MetaData 物件列表。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    if not metadata: return results # Guard against None metadata\n",
    "    data_list = getattr(metadata, metadata_type, []) \n",
    "    for item in data_list:\n",
    "        if item.get(\"階層關係類型\") == category_type or \\\n",
    "           (isinstance(category_type, Enum) and item.get(\"概念類別\") == category_type.value) or \\\n",
    "           (not isinstance(category_type, Enum) and item.get(\"概念類別\") == category_type):\n",
    "            results.append(item)\n",
    "    return results\n",
    "\n",
    "def combined_search_hierarchy(metadata, category_type, related_law_keyword):\n",
    "    \"\"\"\n",
    "    複合條件搜尋法規階層關係 (特定類型 + 關聯法規關鍵字)。\n",
    "    Args:\n",
    "        metadata (LawMetaData): LawMetaData 物件。\n",
    "        category_type (str): 要篩選的階層關係類型 (例如 \"子法規\")。\n",
    "        related_law_keyword (str): 關聯法規名稱中要包含的關鍵字 (例如 \"施行細則\")。\n",
    "    Returns:\n",
    "        list: 符合複合條件的法規階層關係 MetaData 物件列表。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    if not metadata: return results # Guard against None metadata\n",
    "    for relation in metadata.hierarchy_relations:\n",
    "        if relation.get(\"階層關係類型\") == category_type and related_law_keyword.lower() in relation.get(\"關聯法規\", \"\").lower():\n",
    "            results.append(relation)\n",
    "    return results\n",
    "\n",
    "def generate_mermaid_diagram(metadata):\n",
    "    \"\"\"\n",
    "    生成法規關係圖的 mermaid 語法。\n",
    "    Args:\n",
    "        metadata (LawMetaData): LawMetaData 物件。\n",
    "    Returns:\n",
    "        str: mermaid 語法字串。\n",
    "    \"\"\"\n",
    "    mermaid_lines = []\n",
    "    if not metadata: return \"graph TD\\n    %% No metadata provided\"\n",
    "    for relation in metadata.hierarchy_relations:\n",
    "        main_law = relation.get(\"主法規\", \"N/A\")\n",
    "        related_law = relation.get(\"關聯法規\", \"N/A\")\n",
    "        relation_type = relation.get(\"階層關係類型\", \"related\")\n",
    "        mermaid_lines.append(f'    {main_law} -->|{relation_type}| {related_law}')\n",
    "    if not mermaid_lines:\n",
    "        return \"graph TD\\n    %% No hierarchy relations found\"\n",
    "    return \"graph TD\\n\" + \"\\n\".join(mermaid_lines)\n",
    "\n",
    "def generate_article_mermaid_diagram(metadata):\n",
    "    \"\"\"\n",
    "    生成法條關係圖的 mermaid 語法。\n",
    "    Args:\n",
    "        metadata (LawMetaData): LawMetaData 物件。\n",
    "    Returns:\n",
    "        str: mermaid 語法字串。\n",
    "    \"\"\"\n",
    "    mermaid_lines = [\"graph TD\"]\n",
    "    if not metadata: return \"graph TD\\n    %% No metadata provided\"\n",
    "    for article in metadata.law_articles:\n",
    "        article_id = article.get(\"條號\", \"UnknownArticle\")\n",
    "        related_articles_map = article.get(\"法條關聯性\", {}) \n",
    "        for rel_type, related_items in related_articles_map.items():\n",
    "            if related_items and isinstance(related_items, list):\n",
    "                for v_item in related_items:\n",
    "                    v_clean = str(v_item).replace(\"、\",\"_\").replace(\"，\",\"_\").replace(\" \",\"_\").replace(\"『\",\"_\").replace(\"』\",\"_\")\n",
    "                    mermaid_lines.append(f'    A_{article_id}[\"{article_id}\"] --> |{rel_type}| R_{v_clean}[\"{v_item}\"]')\n",
    "    if len(mermaid_lines) == 1:\n",
    "        return \"graph TD\\n    %% No article relations found\"\n",
    "    return \"\\n\".join(mermaid_lines)\n",
    "\n",
    "print(\"Analysis tool functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Analyzing DB-Loaded Data\n",
    "This section demonstrates using the analysis tools defined above with `LawMetadata` objects loaded from the PostgreSQL database.\n",
    "**Prerequisite:** Ensure that a law (e.g., \"政府採購法\" with its corresponding code) has been successfully upserted into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- F. Testing Analysis Tools with DB-Loaded LawMetadata ---\")\n",
    "conn_analysis_db = get_db_connection()\n",
    "lm_db_for_analysis = None\n",
    "\n",
    "if conn_analysis_db:\n",
    "    try:\n",
    "        lmmgr_db_analysis_tools = LawMetadataMgr(db_conn=conn_analysis_db)\n",
    "        \n",
    "        law_code_for_analysis = example_law_code_for_later_use if 'example_law_code_for_later_use' in locals() and example_law_code_for_later_use else \"LT_政府採購法\"\n",
    "        law_name_for_analysis = example_law_name_for_later_use if 'example_law_name_for_later_use' in locals() and example_law_name_for_later_use else \"政府採購法\"\n",
    "        \n",
    "        print(f\"Attempting to load '{law_name_for_analysis}' (code: {law_code_for_analysis}) from DB for analysis...\")\n",
    "        lmmgr_db_analysis_tools.load_lm_from_db(law_pcode_to_load=law_code_for_analysis) #param name updated\n",
    "        lm_db_for_analysis = lmmgr_db_analysis_tools.find_lm(law_name_for_analysis)\n",
    "\n",
    "        if lm_db_for_analysis:\n",
    "            print(f\"\\nSuccessfully loaded '{law_name_for_analysis}' from DB for analysis.\")\n",
    "            \n",
    "            print(f\"\\n--- Keyword Search on DB-loaded '{law_name_for_analysis}' (Keyword: '採購') ---\")\n",
    "            db_keyword_results = keyword_search(lm_db_for_analysis, \"採購\", [\"簡述\", \"定義\"])\n",
    "            if db_keyword_results:\n",
    "                for res in db_keyword_results:\n",
    "                    print(f\"  - Found in: {res.get('詞彙名稱', res.get('法規名稱', 'N/A'))}, Content: {res.get('定義', res.get('簡述', ''))[:100]}...\")\n",
    "            else:\n",
    "                print(\"  No results for keyword search.\")\n",
    "\n",
    "            print(f\"\\n--- Category Filter on DB-loaded '{law_name_for_analysis}' (Category: '子法規') ---\")\n",
    "            db_category_results = category_filter(lm_db_for_analysis, \"子法規\")\n",
    "            if db_category_results:\n",
    "                for res in db_category_results:\n",
    "                    print(f\"  - Main: {res.get('主法規')}, Related: {res.get('關聯法規')}, Type: {res.get('階層關係類型')}\")\n",
    "            else:\n",
    "                print(\"  No results for category filter '子法規'.\")\n",
    "            \n",
    "            print(f\"\\n--- Mermaid Diagram for DB-loaded '{law_name_for_analysis}' (Hierarchy) ---\")\n",
    "            db_mermaid_output = generate_mermaid_diagram(lm_db_for_analysis)\n",
    "            print(db_mermaid_output)\n",
    "        else:\n",
    "            print(f\"Failed to load or find '{law_name_for_analysis}' from DB for analysis. Ensure it was upserted with code '{law_code_for_analysis}'.\")\n",
    "\n",
    "    except Exception as e_analysis_db:\n",
    "        print(f\"An error occurred during DB analysis demonstration: {e_analysis_db}\")\n",
    "    finally:\n",
    "        if conn_analysis_db and not conn_analysis_db.closed:\n",
    "            conn_analysis_db.close()\n",
    "            print(\"\\nDB connection for analysis closed.\")\n",
    "else:\n",
    "    print(\"Failed to connect to DB for analysis demonstration.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0: # Original examples with JSON-loaded data (lmmgr_json_ops)\n",
    "    print(\"\\n--- Testing Analysis Tools with JSON-Loaded LawMetadata (from lmmgr_json_ops) ---\")\n",
    "    # This cell is for comparison, using LawMetadata loaded from JSON files via lmmgr_json_ops.\n",
    "    # Ensure lmmgr_json_ops is initialized and populated (e.g., from cell under '法規管理使用' section if it was run).\n",
    "    if 'lmmgr_json_ops' in locals() and lmmgr_json_ops.lms and len(lmmgr_json_ops.lms) > 0:\n",
    "        first_json_law_name = list(lmmgr_json_ops.lms.keys())[0]\n",
    "        lm_json_test = lmmgr_json_ops.find_lm(first_json_law_name)\n",
    "        \n",
    "        if lm_json_test:\n",
    "            print(f\"Using '{lm_json_test.law_name}' loaded from JSON for comparison.\")\n",
    "            print(f\"\\n--- Keyword Search on JSON-loaded '{lm_json_test.law_name}' (Keyword: '公開') ---\")\n",
    "            json_keyword_results = keyword_search(lm_json_test, \"公開\", [\"簡述\", \"定義\"])\n",
    "            if json_keyword_results:\n",
    "                for res in json_keyword_results:\n",
    "                    print(f\"  - Found in: {res.get('詞彙名稱', res.get('法規名稱', 'N/A'))}, Content: {res.get('定義', res.get('簡述', ''))[:100]}...\")\n",
    "            else:\n",
    "                print(\"  No results for keyword search.\")\n",
    "\n",
    "            print(f\"\\n--- Category Filter on JSON-loaded '{lm_json_test.law_name}' (Category: '子法規') ---\")\n",
    "            json_category_results = category_filter(lm_json_test, \"子法規\")\n",
    "            if json_category_results:\n",
    "                for res in json_category_results:\n",
    "                    print(f\"  - Main: {res.get('主法規')}, Related: {res.get('關聯法規')}, Type: {res.get('階層關係類型')}\")\n",
    "            else:\n",
    "                print(\"  No results for category filter '子法規'.\")\n",
    "            \n",
    "            print(f\"\\n--- Mermaid Diagram for JSON-loaded '{lm_json_test.law_name}' (Hierarchy) ---\")\n",
    "            json_mermaid_output = generate_mermaid_diagram(lm_json_test)\n",
    "            print(json_mermaid_output)\n",
    "        else:\n",
    "            print(f\"Could not find law '{first_json_law_name}' in lmmgr_json_ops to run JSON-based analysis tests.\")\n",
    "    else:\n",
    "        print(\"LawMetadata manager for JSON (lmmgr_json_ops) not populated or empty. Skipping JSON-based analysis tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 單法規使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "law_name = \"政府採購法施行細則\" # Or dynamically extract from law_regulation.json if needed\n",
    "\n",
    "filepaths = {\n",
    "    \"law_regulation\": f\"{dir_json}/{law_name}_law_regulation.json\",\n",
    "    \"legal_concepts\": f\"{dir_json}/{law_name}_legal_concepts.json\",\n",
    "    \"hierarchy_relations\": f\"{dir_json}/{law_name}_hierarchy_relations.json\",\n",
    "    \"law_relations\": f\"{dir_json}/{law_name}_law_relations.json\",\n",
    "    \"law_articles\": f\"{dir_json}/{law_name}_law_articles.json\"\n",
    "}\n",
    "\n",
    "\n",
    "# 1. Read from separate JSON files and create LawMetadata object\n",
    "lm = LawMetadata.from_json_files(**filepaths)\n",
    "\n",
    "\n",
    "if lm:\n",
    "    print(lm)\n",
    "\n",
    "    # 2. Access Metadata content (example)\n",
    "    print(\"\\nLaw Regulation Name:\", lm.law_regulation.get(\"法規名稱\"))\n",
    "    print(\"\\nFirst Legal Concept Name:\", lm.legal_concepts[0].get(\"詞彙名稱\"))\n",
    "\n",
    "    if 0:\n",
    "        lm.renew_id()\n",
    "    # 3. Modify Metadata content (example)\n",
    "    if 0:\n",
    "        lm.law_regulation[\"版本\"] = \"20250312-Test Version\"\n",
    "        new_concept = {\n",
    "            \"代號\": \"concept-gpa-new-concept\",\n",
    "            \"詞彙名稱\": \"New Concept\",\n",
    "            \"定義\": \"This is a new concept definition.\",\n",
    "            \"相關概念\": [],\n",
    "            \"相關法條\": [],\n",
    "            \"概念類別\": \"新增概念\",\n",
    "            \"同義詞\": [],\n",
    "            \"台灣觀點\": \"Taiwan Viewpoint.\",\n",
    "            \"範例\": \"Example here.\",\n",
    "            \"語意向量\": \"[]\"\n",
    "        }\n",
    "        lm.legal_concepts.append(new_concept)\n",
    "if 0:\n",
    "    # 4. Export LawMetadata object to separate JSON files\n",
    "    lm.to_json_files(output_prefix=f\"{dir_json}/{law_name}_M\") # Exports to gpa_modified_*.json\n",
    "if 1:\n",
    "    conn = get_db_connection()\n",
    "    upsert_law_metadata_to_db(lm,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 法規管理使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0: #法律管理\n",
    "    lmmgr = LawMetadataMgr()\n",
    "    law_names = get_law_names_from_directory(\"./json\")\n",
    "    #print(law_names)\n",
    "    #lmmgr.load_lm_bynames([\"憲法合併\",\"憲法增修合併\",\"刑法\",\"民法\",\"行政程序法\",\"預算法\",\"政府採購法\",\"政府採購法施行細則\"])\n",
    "    lmmgr.load_lm_bynames_from_json(law_names)   \n",
    "    lms = lmmgr.lms\n",
    "if 0: #法律列表\n",
    "    for law_name in lms.keys():\n",
    "        #print(f\"{lms[law_name].law_name}-{lms[law_name].short_name}\" )\n",
    "        print(f\"{lms[law_name].law_name}\" )\n",
    "if 0: #法律概念列表\n",
    "    for law_name in lms.keys():\n",
    "        print(f\"----- {law_name} -----\")\n",
    "        for lc in lms[law_name].legal_concepts:\n",
    "            print(f\"{lc['詞彙名稱']}\")\n",
    "    #print(lms['中華民國憲法(合併增修條文)'].legal_concepts)\n",
    "if 0: # 某法跟什麼法有關係如 公司法\n",
    "    target = \"公司法\"\n",
    "    for law_name in lms.keys():\n",
    "        if target in lms[law_name].law_regulation['相關法規']:\n",
    "            print(f\"{law_name} 跟 {target} 有關係\")\n",
    "if 1: # 某個關鍵字的總覽\n",
    "   \n",
    "    pass\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM 建構 json\n",
    "- 由於 LLM 的產出有時遇到小問題，所以使用時暫時需開開關關"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "# from google import genai # Assuming genai might not be available in all test environments\n",
    "# from google.genai import types\n",
    "import time\n",
    "\n",
    "def generate(client,files,law_name,user_prompt,file_path):\n",
    "    # This function is a placeholder if genai is not available.\n",
    "    # To use it, ensure google.genai is installed and configured.\n",
    "    print(f\"[INFO] Generate function called for {law_name} with prompt: {user_prompt[:50]}...\")\n",
    "    print(f\"[INFO] Output would be written to {file_path}\")\n",
    "    # Actual generation logic commented out for environments without genai\n",
    "    \"\"\"\n",
    "    model = \"gemini-2.0-flash-thinking-exp-01-21\"\n",
    "    if 1:\n",
    "        contents = [\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part.from_uri(\n",
    "                        file_uri=files[0].uri,\n",
    "                        mime_type=files[0].mime_type,\n",
    "                    ),\n",
    "                    types.Part.from_uri(\n",
    "                        file_uri=files[1].uri,\n",
    "                        mime_type=files[1].mime_type,\n",
    "                    ),\n",
    "                    types.Part.from_text(text=user_prompt),\n",
    "                ],\n",
    "            )\n",
    "        ]\n",
    "        generate_content_config = types.GenerateContentConfig(\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            top_k=64,\n",
    "            max_output_tokens=65536,\n",
    "            response_mime_type=\"text/plain\",\n",
    "            system_instruction=[\n",
    "                types.Part.from_text(text=\"\"\"請以台灣人的立場，用繁體中文回答\"\"\"),\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        print(f\"Q::{user_prompt}\")\n",
    "\n",
    "        response_text = \"\"\n",
    "        for chunk in client.models.generate_content_stream(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "            config=generate_content_config,\n",
    "        ):\n",
    "            response_text += chunk.text\n",
    "            #print(chunk.text, end=\"\")\n",
    "        print(f\"A::{response_text}\")\n",
    "\n",
    "        try:\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Q::{user_prompt}\\n\")\n",
    "                file.write(f\"A::{response_text}\")\n",
    "                print(f\"Content written to {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \"\"\"\n",
    "    pass # Placeholder if genai is not used\n",
    "\n",
    "api_key=os.environ.get(\"GEMINI_API_KEY\")\n",
    "client = None # Placeholder for genai.Client\n",
    "files_for_llm = [] # Placeholder for uploaded files\n",
    "\n",
    "law_name=\"憲法增修合併\" # Example law name for LLM section\n",
    "\n",
    "if 0: # This entire LLM section is turned off by default for this refactoring step\n",
    "    # Ensure google.genai is imported and client is initialized if this block is enabled\n",
    "    # client = genai.Client(api_key=api_key)\n",
    "    # files_for_llm = [\n",
    "    #     client.files.upload(file=f\"{law_name}.md\",config={'mime_type':\"text/markdown\"}),\n",
    "    #     client.files.upload(file=\"法律語法形式化.md\",config={'mime_type':\"text/markdown\"}),\n",
    "    # ]\n",
    "    pass\n",
    "\n",
    "if 0: # 產生非法條的 Meta data (Turned off)\n",
    "    prompt_list=[\n",
    "        ['law_regulation',f\"\"\"根據{law_name}的整體資訊，按照法律語法形式化的設計，依照裡面範例格式，產生法規 Meta Data,盡可能詳列資訊，不要省略\"\"\"],\n",
    "        ['legal_concepts',f\"\"\"根據{law_name}的整體資訊，按照法律語法形式化的設計，依照裡面範例格式，產生法律概念 Meta Data (Legal Concept Meta Data)，注意並非 法規 Meta Data，請列出全部概念，不要省略\"\"\"],\n",
    "        ['hierarchy_relations',f\"\"\"根據{law_name}的整體資訊，按照法律語法形式化的設計，依照裡面範例格式，產生法規階層關係 Meta Data，不包含法條間關聯性，請列出全部法規間階層關係，尤其包含上位關係，不要省略\"\"\"],\n",
    "        ['law_relations',f\"\"\"根據{law_name}的整體資訊，按照法律語法形式化的設計，依照裡面範例格式，產生法規關聯性 Meta Data，不包含本法規內部法條之間的關聯性，請列出法規間全部關聯性，不要省略\"\"\"]\n",
    "    ]\n",
    "    for prompt_pair in prompt_list:\n",
    "        file_path_txt = f\"{dir_txt}/{law_name}_{prompt_pair[0]}.txt\"\n",
    "        if client and files_for_llm: generate(client,files_for_llm,law_name,prompt_pair[1],file_path_txt)\n",
    "        \n",
    "        file_path_json = f\"{dir_json}/{law_name}_{prompt_pair[0]}.json\"\n",
    "        if os.path.exists(file_path_txt):\n",
    "            regex = r\"```(?:json)*\\n(.*)```\"\n",
    "            lines = handle_regex(regex,file_path_txt,\"col1\")\n",
    "            if lines:\n",
    "                json_string = \"\\n\".join(lines)\n",
    "                json_string = re.sub(r'//.*', '', json_string)\n",
    "                json_string = re.sub(r'# .*', '', json_string)\n",
    "                try:\n",
    "                    json_object = json.loads(json_string)\n",
    "                    print(json_object)\n",
    "                    with open(file_path_json, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(json_object, f, indent=2, ensure_ascii=False)\n",
    "                except json.JSONDecodeError as je:\n",
    "                    print(f\"JSON Decode Error for {file_path_txt}: {je}\")\n",
    "            else:\n",
    "                print(f\"No JSON content found in {file_path_txt}\")\n",
    "\n",
    "if 0: # 取得最大條號 ，也可手動填入結果 (Turned off)\n",
    "    # ... (LLM code remains off for this refactoring)\n",
    "    pass\n",
    "    \n",
    "if 0: # 產生法條 Meta Data (Turned off)\n",
    "    # ... (LLM code remains off for this refactoring)\n",
    "    pass\n",
    "\n",
    "if 0: #從檔案內組合法條 Meta data (Turned off)\n",
    "    # ... (LLM code remains off for this refactoring)\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2504",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
