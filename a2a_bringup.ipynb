{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9bba095",
   "metadata": {},
   "source": [
    "# 想帶起 A2A agent with mcp client + LLM\n",
    "env: M2504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to run main() using asyncio.run()...\n",
      "asyncio.run() failed: An event loop is already running.\n",
      "Attempting to run main() on the existing event loop using loop.run_until_complete()...\n",
      "loop.run_until_complete() also failed: This event loop is already running\n",
      "As a final fallback, creating a task for main() on the running loop.\n",
      "Note: Output from main() might appear asynchronously or be incomplete in this mode.\n",
      "Creating task for main() as loop is running.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/6z_8fjy91fxbyxf66g1mnlxr0000gn/T/ipykernel_32717/3162466684.py:-1: RuntimeWarning: coroutine 'main' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastmcp client logging level set to DEBUG.\n",
      "Initializing MCP client with transport config: {\"mcpServers\": {\"postgres-mcp-server\": {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://root:LN3F5E8iGs67HDRlZWOehT0yJ2a4m19k@211.73.81.235:30198/zeabur\"], \"transportType\": \"stdio\"}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/6z_8fjy91fxbyxf66g1mnlxr0000gn/T/ipykernel_32717/3162466684.py:40: RuntimeWarning: coroutine 'Client.set_logging_level' was never awaited\n",
      "  self.mcp_client_instance.set_logging_level(\"DEBUG\") # Attempt to set logging level\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A runtime error occurred during initial tool discovery: Failed to initialize server session\n",
      "This error often indicates a problem with the MCP server process itself or its ability to start/maintain connection.\n",
      "The client attempted to start/connect to the following command:\n",
      "  Command: npx\n",
      "  Arguments: -y @modelcontextprotocol/server-postgres postgresql://root:LN3F5E8iGs67HDRlZWOehT0yJ2a4m19k@211.73.81.235:30198/zeabur\n",
      "\\nPossible causes include:\n",
      "1. Invalid PostgreSQL Connection String: The string used to connect to your PostgreSQL server might be incorrect (e.g., wrong credentials, host/port, database name), or the PostgreSQL server might be down or inaccessible.\n",
      "2. `npx` or MCP Server Package Issues: Problems with `npx` or the `@modelcontextprotocol/server-postgres` package (e.g., not installed correctly, internal script errors, missing dependencies for the script).\n",
      "3. Network Configuration: Firewalls or other network issues preventing the MCP server script from reaching the PostgreSQL database or the client from reaching the server.\n",
      "4. Environment Issues: The environment where the notebook kernel is running might be missing necessary PATH configurations for `npx` or Node.js, or there might be permission issues.\n",
      "\\nDebugging Steps:\n",
      "A. Verify the PostgreSQL connection string and ensure the database is accessible with the provided credentials (e.g., using a separate SQL client).\n",
      "B. Try running the MCP server command directly in your system's terminal (outside of the notebook environment) to see if it outputs any specific errors. This helps isolate if the issue is with the command itself or the notebook's execution environment:\n",
      "   npx -y @modelcontextprotocol/server-postgres postgresql://root:LN3F5E8iGs67HDRlZWOehT0yJ2a4m19k@211.73.81.235:30198/zeabur\n",
      "C. Check if `npx` and `node` are correctly installed and accessible from the environment where your Jupyter notebook kernel is running. You can try running `!npx --version` or `!node --version` in a new notebook cell.\n",
      "D. Examine the full traceback printed below (if any) for more detailed clues from the `fastmcp` library or the subprocess management.\n",
      "\\nSkipping example tool-based queries as no tools were available or an error occurred during discovery.\n",
      "Tools not fetched or no tools available. Attempting to fetch now...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/4y/6z_8fjy91fxbyxf66g1mnlxr0000gn/T/ipykernel_32717/3162466684.py\", line 193, in main\n",
      "    available_tools_formatted = await client.connect_and_fetch_tools()\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4y/6z_8fjy91fxbyxf66g1mnlxr0000gn/T/ipykernel_32717/3162466684.py\", line 50, in connect_and_fetch_tools\n",
      "    async with self.mcp_client_instance as session: # session is the active Client instance\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/site-packages/fastmcp/client/client.py\", line 187, in __aenter__\n",
      "    await stack.enter_async_context(self._context_manager())\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/contextlib.py\", line 659, in enter_async_context\n",
      "    result = await _enter(cm)\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/site-packages/fastmcp/client/client.py\", line 164, in _context_manager\n",
      "    with catch(get_catch_handlers()):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/site-packages/exceptiongroup/_catch.py\", line 39, in __exit__\n",
      "    raise unhandled from exc.__cause__\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/site-packages/exceptiongroup/_catch.py\", line 65, in handle_exception\n",
      "    result = handler(matched)\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/site-packages/fastmcp/utilities/exceptions.py\", line 29, in _exception_handler\n",
      "    raise leaf\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/site-packages/fastmcp/client/transports.py\", line 254, in connect_session\n",
      "    yield session\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/site-packages/fastmcp/client/transports.py\", line 572, in connect_session\n",
      "    yield session\n",
      "  File \"/Users/wuulong/opt/anaconda3/envs/m2504/lib/python3.12/site-packages/fastmcp/client/client.py\", line 175, in _context_manager\n",
      "    raise RuntimeError(\"Failed to initialize server session\")\n",
      "RuntimeError: Failed to initialize server session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP client session active. Discovering tools for server 'postgres-mcp-server' using 'tools/list'...\n",
      "Error during 'tools/list' call for server 'postgres-mcp-server': Unknown tool: tools/list\n",
      "Error fetching tools during request processing: Unknown tool: tools/list\n",
      "\\nFinal Response for 'Tell me a joke.': Sorry, I encountered an error trying to fetch tools: Unknown tool: tools/list\n"
     ]
    }
   ],
   "source": [
    "# MCP client with LLM\n",
    "\n",
    "# main_client.py\n",
    "import asyncio\n",
    "from fastmcp.client import Client # Removed ClientSession import\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "# from google.generativeai.types import Part\n",
    "\n",
    "# --- 配置 Gemini ---\n",
    "GEMINI_API_KEY = \"AIzaSyDd5iMMMaFO76c17-XFIlaBIvD1lk2gjY8\" # User's API Key\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "gemini_model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# --- MCP Client 實例 ---\n",
    "class GeminiEnhancedMCPClient:\n",
    "    def __init__(self, mcp_command, mcp_args, mcp_transport_type=\"stdio\"):\n",
    "        self.mcp_command = mcp_command\n",
    "        self.mcp_args = mcp_args\n",
    "        self.mcp_transport_type = mcp_transport_type\n",
    "        \n",
    "        # Configuration for a single server, matching StdioMCPServer/RemoteMCPServer fields\n",
    "        single_server_details = {\n",
    "            \"command\": self.mcp_command,\n",
    "            \"args\": self.mcp_args,\n",
    "            \"transportType\": self.mcp_transport_type\n",
    "        }\n",
    "        \n",
    "        # mcpServers should be a dictionary mapping server names to their configs\n",
    "        self.server_name = \"postgres-mcp-server\" # Store server name for easy access\n",
    "        mcp_client_config = {\n",
    "            \"mcpServers\": {\n",
    "                self.server_name: single_server_details # Server name as key\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.client_config = mcp_client_config # Store config for re-use if needed\n",
    "        self.mcp_client_instance = Client(self.client_config) # Create client instance once\n",
    "        try:\n",
    "            self.mcp_client_instance.set_logging_level(\"DEBUG\") # Attempt to set logging level\n",
    "            print(\"fastmcp client logging level set to DEBUG.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not set fastmcp client logging level: {e}\")\n",
    "            \n",
    "        print(f\"Initializing MCP client with transport config: {json.dumps(self.client_config)}\")\n",
    "        self.mcp_tools_cache = None\n",
    "        # self.current_session will be managed by async with block in methods\n",
    "\n",
    "    async def connect_and_fetch_tools(self):\n",
    "        async with self.mcp_client_instance as session: # session is the active Client instance\n",
    "            print(f\"MCP client session active. Discovering tools for server '{self.server_name}' using 'tools/list'...\")\n",
    "            \n",
    "            try:\n",
    "                print(\"Wuulnog1\")\n",
    "                raw_tools_response = await session.call_tool(\"tools/list\", {})\n",
    "                print(f\"Raw response from MCP server '{self.server_name}' for 'tools/list': {raw_tools_response}\")\n",
    "\n",
    "                actual_tools_list = None\n",
    "                potential_result_part = None\n",
    "\n",
    "                if isinstance(raw_tools_response, dict):\n",
    "                    if 'result' in raw_tools_response: # Full JSON-RPC response\n",
    "                        potential_result_part = raw_tools_response['result']\n",
    "                    else: # Assuming raw_tools_response is already the result part itself\n",
    "                        potential_result_part = raw_tools_response\n",
    "                    \n",
    "                    if isinstance(potential_result_part, dict): # e.g. {\"tools\": [...]}\n",
    "                        actual_tools_list = potential_result_part.get(\"tools\")\n",
    "                    elif isinstance(potential_result_part, list): # e.g. [...] list of tools\n",
    "                        actual_tools_list = potential_result_part\n",
    "                        # Validate if items are indeed tool dictionaries\n",
    "                        if not all(isinstance(item, dict) for item in actual_tools_list):\n",
    "                            print(f\"Warning: Result part is a list, but items are not all dictionaries (tools). Content: {actual_tools_list}\")\n",
    "                            actual_tools_list = None # Reset if format is unexpected\n",
    "                \n",
    "                elif isinstance(raw_tools_response, list): # If call_tool directly returns the list of tools\n",
    "                    actual_tools_list = raw_tools_response\n",
    "                    # Validate if items are indeed tool dictionaries\n",
    "                    if not all(isinstance(item, dict) for item in actual_tools_list):\n",
    "                        print(f\"Warning: Raw response is a list, but items are not all dictionaries (tools). Content: {actual_tools_list}\")\n",
    "                        actual_tools_list = None # Reset if format is unexpected\n",
    "                \n",
    "                if actual_tools_list is None:\n",
    "                    print(f\"Warning: Could not extract tool list. Structure not as expected or 'tools' key missing. Response: {raw_tools_response}\")\n",
    "                    actual_tools_list = [] # Proceed with an empty list to prevent downstream errors\n",
    "\n",
    "                self.mcp_tools_cache = self._format_tools_for_gemini(actual_tools_list)\n",
    "                return self.mcp_tools_cache\n",
    "            except Exception as e:\n",
    "                print(f\"Error during 'tools/list' call for server '{self.server_name}': {e}\")\n",
    "                # Re-raise the exception to be caught by the main try-except block\n",
    "                raise\n",
    "\n",
    "\n",
    "    def _format_tools_for_gemini(self, raw_tools_list): # Renamed raw_tools to raw_tools_list for clarity\n",
    "        gemini_tools = []\n",
    "        if isinstance(raw_tools_list, list):\n",
    "            for tool_info in raw_tools_list:\n",
    "                if isinstance(tool_info, dict):\n",
    "                    name = tool_info.get(\"name\")\n",
    "                    description = tool_info.get(\"description\")\n",
    "                    # Use \"inputSchema\" from server response for Gemini's \"parameters\"\n",
    "                    input_schema = tool_info.get(\"inputSchema\") \n",
    "                    if name and description and input_schema is not None:\n",
    "                        gemini_tools.append({\n",
    "                            \"name\": name,\n",
    "                            \"description\": description,\n",
    "                            \"parameters\": input_schema # Assign input_schema here\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"Warning: Skipping tool due to missing fields (name, description, or inputSchema): {tool_info}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Expected a dictionary for tool_info, but got {type(tool_info)}. Skipping this tool.\")\n",
    "        else:\n",
    "            print(f\"Warning: Expected a list of tools from the server, but got {type(raw_tools_list)}. No tools will be formatted.\")\n",
    "        return [{\"function_declarations\": gemini_tools}]\n",
    "\n",
    "    async def process_user_request(self, user_query): # Changed to async def\n",
    "        if not self.mcp_tools_cache or not self.mcp_tools_cache[0].get(\"function_declarations\"):\n",
    "            print(\"Tools not fetched or no tools available. Attempting to fetch now...\")\n",
    "            try:\n",
    "                await self.connect_and_fetch_tools() # Added await\n",
    "                if not self.mcp_tools_cache or not self.mcp_tools_cache[0].get(\"function_declarations\"):\n",
    "                    return \"Sorry, I couldn't retrieve any tools from the server after attempting to connect.\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching tools during request processing: {e}\")\n",
    "                # Re-raise to allow main to catch it or return a user-friendly message\n",
    "                # For now, returning a message. Consider re-raising if main should handle all.\n",
    "                return f\"Sorry, I encountered an error trying to fetch tools: {e}\"\n",
    "        \n",
    "        print(f\"\\\\nProcessing user query: '{user_query}' with Gemini and MCP tools...\")\n",
    "        \n",
    "        try:\n",
    "            # gemini_model.generate_content is synchronous.\n",
    "            response = gemini_model.generate_content(\n",
    "                f\"User query: {user_query}\",\n",
    "                tools=self.mcp_tools_cache\n",
    "            )\n",
    "\n",
    "            if response.candidates and response.candidates[0].content.parts and response.candidates[0].content.parts[0].function_call:\n",
    "                function_call = response.candidates[0].content.parts[0].function_call\n",
    "                tool_name = function_call.name\n",
    "                tool_args = {key: value for key, value in function_call.args.items()}\n",
    "                \n",
    "                print(f\"Gemini suggests calling tool: {tool_name} with args: {tool_args}\")\n",
    "                print(f\"MCP client session active. Invoking tool '{tool_name}' on server '{self.server_name}'...\")\n",
    "                \n",
    "                async with self.mcp_client_instance as session_for_invoke: # session_for_invoke is the active Client instance\n",
    "                    # Directly call the tool using session_for_invoke.call_tool\n",
    "                    # Removed server_name argument\n",
    "                    tool_result = await session_for_invoke.call_tool(tool_name, tool_args)\n",
    "                \n",
    "                print(f\"Received result from MCP server for tool '{tool_name}': {tool_result}\")\n",
    "                return tool_result\n",
    "            else:\n",
    "                print(\"Gemini responded directly without tool usage.\")\n",
    "                # Ensure response.text is accessed safely\n",
    "                try:\n",
    "                    return response.text\n",
    "                except ValueError: # Handle cases where response.text might not be available (e.g. blocked response)\n",
    "                    print(\"Warning: Gemini response did not contain a direct text part (e.g. safety block).\")\n",
    "                    if response.prompt_feedback:\n",
    "                        print(f\"Prompt feedback: {response.prompt_feedback}\")\n",
    "                    return \"Gemini did not provide a text response.\"\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during Gemini processing or MCP interaction: {e}\")\n",
    "            # Re-raise the exception to be caught by the main try-except block\n",
    "            raise\n",
    "\n",
    "# --- 使用範例 ---\n",
    "async def main(): # Wrapped in async main\n",
    "    mcp_server_config = {\n",
    "        \"command\": \"npx\",\n",
    "        \"args\": [\n",
    "            \"-y\",\n",
    "            \"@modelcontextprotocol/server-postgres\",\n",
    "            \"postgresql://root:LN3F5E8iGs67HDRlZWOehT0yJ2a4m19k@211.73.81.235:30198/zeabur\"\n",
    "        ],\n",
    "        \"transportType\": \"stdio\"\n",
    "    }\n",
    "\n",
    "    client = GeminiEnhancedMCPClient(\n",
    "        mcp_command=mcp_server_config[\"command\"],\n",
    "        mcp_args=mcp_server_config[\"args\"],\n",
    "        mcp_transport_type=mcp_server_config[\"transportType\"]\n",
    "    )\n",
    "    \n",
    "    available_tools_formatted = []\n",
    "    actual_tools_list = []\n",
    "    try:\n",
    "        \n",
    "        available_tools_formatted = await client.connect_and_fetch_tools()\n",
    "        print(f\"\\\\nAvailable tools (formatted for Gemini by the client): {json.dumps(available_tools_formatted, indent=2, ensure_ascii=False)}\")\n",
    "        \n",
    "        if available_tools_formatted and available_tools_formatted[0].get(\"function_declarations\"):\n",
    "            actual_tools_list = available_tools_formatted[0][\"function_declarations\"]\n",
    "            if actual_tools_list:\n",
    "                print(\"\\\\n--- List of Discovered Tools ---\")\n",
    "                for i, tool in enumerate(actual_tools_list):\n",
    "                    print(f\"{i+1}. Name: {tool.get('name')}\")\n",
    "                    print(f\"   Description: {tool.get('description')}\")\n",
    "                    print(f\"   Parameters: {json.dumps(tool.get('parameters'), indent=2, ensure_ascii=False)}\")\n",
    "                print(\"-------------------------------\")\n",
    "            else:\n",
    "                print(\"\\\\nNo tools found in function_declarations after formatting.\")\n",
    "        else:\n",
    "            print(\"\\\\nNo tools were discovered or formatted correctly (function_declarations missing or empty).\")\n",
    "\n",
    "    except (ConnectionRefusedError, ConnectionResetError, ConnectionAbortedError, ConnectionError) as conn_err:\n",
    "        print(f\"A connection error occurred during initial tool discovery: {conn_err}\")\n",
    "        print(\"This often indicates the MCP server process could not be reached or terminated unexpectedly.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    except RuntimeError as rt_err: # Catch specific RuntimeErrors if needed, or broaden\n",
    "        print(f\"A runtime error occurred during initial tool discovery: {rt_err}\")\n",
    "        if \"Failed to initialize server session\" in str(rt_err) or \\\n",
    "           \"Server process exited\" in str(rt_err) or \\\n",
    "           \"Server process failed to start\" in str(rt_err) or \\\n",
    "           \"Connection to server process lost\" in str(rt_err): # Added more specific checks\n",
    "            print(\"This error often indicates a problem with the MCP server process itself or its ability to start/maintain connection.\")\n",
    "            print(f\"The client attempted to start/connect to the following command:\")\n",
    "            print(f\"  Command: {client.mcp_command}\")\n",
    "            print(f\"  Arguments: {' '.join(client.mcp_args)}\")\n",
    "            print(\"\\\\nPossible causes include:\")\n",
    "            print(\"1. Invalid PostgreSQL Connection String: The string used to connect to your PostgreSQL server might be incorrect (e.g., wrong credentials, host/port, database name), or the PostgreSQL server might be down or inaccessible.\")\n",
    "            print(\"2. `npx` or MCP Server Package Issues: Problems with `npx` or the `@modelcontextprotocol/server-postgres` package (e.g., not installed correctly, internal script errors, missing dependencies for the script).\")\n",
    "            print(\"3. Network Configuration: Firewalls or other network issues preventing the MCP server script from reaching the PostgreSQL database or the client from reaching the server.\")\n",
    "            print(\"4. Environment Issues: The environment where the notebook kernel is running might be missing necessary PATH configurations for `npx` or Node.js, or there might be permission issues.\")\n",
    "            print(\"\\\\nDebugging Steps:\")\n",
    "            print(\"A. Verify the PostgreSQL connection string and ensure the database is accessible with the provided credentials (e.g., using a separate SQL client).\")\n",
    "            print(\"B. Try running the MCP server command directly in your system's terminal (outside of the notebook environment) to see if it outputs any specific errors. This helps isolate if the issue is with the command itself or the notebook's execution environment:\")\n",
    "            print(f\"   {client.mcp_command} {' '.join(client.mcp_args)}\")\n",
    "            print(\"C. Check if `npx` and `node` are correctly installed and accessible from the environment where your Jupyter notebook kernel is running. You can try running `!npx --version` or `!node --version` in a new notebook cell.\")\n",
    "            print(\"D. Examine the full traceback printed below (if any) for more detailed clues from the `fastmcp` library or the subprocess management.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during initial tool discovery: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "    if actual_tools_list:\n",
    "        print(\"\\\\nNote: Please inspect the 'List of Discovered Tools' above and craft queries that match available tools and their parameters.\")\n",
    "        # Example: If a tool 'execute_sql' is discovered, you might try:\n",
    "        user_query_sql = \"Execute SQL: SELECT version()\" # Example query for the 'query' tool\n",
    "        print(f\"\\\\nAttempting to process example query: '{user_query_sql}'\")\n",
    "        try:\n",
    "            response_sql = await client.process_user_request(user_query_sql)\n",
    "            print(f\"\\\\nFinal Response for '{user_query_sql}': {response_sql}\")\n",
    "        except Exception as e_query:\n",
    "            print(f\"\\\\nError processing query '{user_query_sql}': {e_query}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"\\\\nSkipping example tool-based queries as no tools were available or an error occurred during discovery.\")\n",
    "\n",
    "    user_query_direct = \"Tell me a joke.\"\n",
    "    try:\n",
    "        response_direct = await client.process_user_request(user_query_direct)\n",
    "        print(f\"\\\\nFinal Response for '{user_query_direct}': {response_direct}\")\n",
    "    except Exception as e_direct_query:\n",
    "        print(f\"\\\\nError processing direct query '{user_query_direct}': {e_direct_query}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if 1: #__name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Attempting to run main() using asyncio.run()...\")\n",
    "        asyncio.run(main())\n",
    "        print(\"main() completed via asyncio.run().\")\n",
    "    except RuntimeError as e:\n",
    "        if \"cannot be called from a running event loop\" in str(e).lower():\n",
    "            print(\"asyncio.run() failed: An event loop is already running.\")\n",
    "            print(\"Attempting to run main() on the existing event loop using loop.run_until_complete()...\")\n",
    "            loop = asyncio.get_event_loop()\n",
    "            try:\n",
    "                loop.run_until_complete(main())\n",
    "                print(\"main() completed via loop.run_until_complete() on existing loop.\")\n",
    "            except RuntimeError as e2:\n",
    "                print(f\"loop.run_until_complete() also failed: {e2}\")\n",
    "                print(\"As a final fallback, creating a task for main() on the running loop.\")\n",
    "                print(\"Note: Output from main() might appear asynchronously or be incomplete in this mode.\")\n",
    "                # Ensure the task is actually awaited or managed if it's critical to see its completion/errors\n",
    "                # For a script-like execution in a notebook, this might be tricky.\n",
    "                # If the loop is already running (e.g. Jupyter), creating a task is often the way.\n",
    "                if loop.is_running():\n",
    "                    print(\"Creating task for main() as loop is running.\")\n",
    "                    task = loop.create_task(main())\n",
    "                    # To actually wait for it in a notebook cell if it's the last operation,\n",
    "                    # you might need a way to keep the cell running or await the task.\n",
    "                    # However, for now, just creating it as per the original logic.\n",
    "                else:\n",
    "                    print(\"Loop is not running, cannot create task for main(). This state is unexpected here.\")\n",
    "\n",
    "        elif \"no current event loop\" in str(e).lower():\n",
    "            print(\"asyncio.run() failed: No current event loop found. This is unexpected.\")\n",
    "            print(\"Manually creating a new event loop and running main()...\")\n",
    "            new_loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(new_loop)\n",
    "            try:\n",
    "                new_loop.run_until_complete(main())\n",
    "                print(\"main() completed on a manually created new event loop.\")\n",
    "            finally:\n",
    "                new_loop.close()\n",
    "                asyncio.set_event_loop(None) \n",
    "        else:\n",
    "            print(f\"An unexpected RuntimeError occurred in asyncio.run()/loop management: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # raise # Optionally re-raise\n",
    "    except Exception as ex:\n",
    "        print(f\"An error occurred at the outermost execution level of main(): {ex}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2504",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
